<!DOCTYPE html>
<html lang="en"><head>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-7b4406b7675125bc2ba204020e191172.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.22">

  <title>Emmanuel Pilliat – The Logistic Model</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/theme/quarto-a9356234971a534880724c4687078043.css">
  <link rel="stylesheet" href="../../../styles.css">
  <link href="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">The Logistic Model</h1>

<div class="quarto-title-authors">
</div>

</section>
<section class="slide level2">

<p><span class="math inline">\(\newcommand{\VS}{\quad \mathrm{VS} \quad}\)</span> <span class="math inline">\(\newcommand{\and}{\quad \mathrm{and} \quad}\)</span> <span class="math inline">\(\newcommand{\E}{\mathbb E}\)</span> <span class="math inline">\(\newcommand{\P}{\mathbb P}\)</span> <span class="math inline">\(\newcommand{\Var}{\mathbb V}\)</span> <span class="math inline">\(\newcommand{\Cov}{\mathrm{Cov}}\)</span> <span class="math inline">\(\newcommand{\1}{\mathbf 1}\)</span></p>
</section>
<section>
<section id="glm-models-for-binary-variables" class="title-slide slide level1 center">
<h1>GLM Models for Binary Variables</h1>

</section>
<section id="context" class="slide level2">
<h2>Context</h2>
<aside class="notes">
<p>Let’s now focus specifically on the binary case and work through it in detail.</p>
<p>Y is a binary variable—Y_k is in {0,1}.</p>
<p>X equals (X^(1) through X^(p)) are our p explanatory variables or regressors.</p>
<p>Y given X equals x follows a Bernoulli distribution with parameter p(x), which equals the probability that Y equals 1 given X equals x.</p>
<p>We model p(x) as g-inverse of x-transpose-beta.</p>
<p>Where g-inverse is a strictly increasing function with values in [0,1]. This ensures our probabilities are valid.</p>
<p>We’ll begin by discussing how to choose g-inverse—or equivalently, the link function g.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<p><span class="math inline">\(Y\)</span> is a binary variable <span style="background-color: lightblue;"><span class="math inline">\(Y_k \in \{0,1\}\)</span></span></p>
<div class="fragment">
<p><span class="math inline">\(X = (X^{(1)}, \ldots, X^{(p)})\)</span> are <span class="math inline">\(p\)</span> regressors</p>
</div>
<div class="fragment">
<p><span class="math inline">\(Y|X = x\)</span> follows a <span style="background-color: yellow;">Bernoulli distribution</span> with parameter <span style="background-color: lightblue;"><span class="math inline">\(p(x) = P(Y = 1|X = x)\)</span></span>. Model:</p>
</div>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[p(x) = g^{-1}(x^T\beta)\]</span></p>
</div>
<p>where <span class="math inline">\(g^{-1}\)</span> is a <span style="background-color: yellow;">strictly increasing function</span> with values in <span class="math inline">\([0, 1]\)</span></p>
</div>
<div class="fragment">
<p><strong>Approach</strong>: We begin by discussing the choice of <span class="math inline">\(g^{-1}\)</span> (or <span class="math inline">\(g\)</span>)</p>
</div>
</section>
<section id="example-coronary-heart-disease" class="slide level2">
<h2>Example: Coronary Heart Disease</h2>
<aside class="notes">
<p>Let’s work through a concrete example to see how this works in practice.</p>
<p>We have data on the presence of coronary heart disease—chd—as a function of age. So Y equals chd, taking values 0 or 1, and X equals age.</p>
<p>We want to estimate p(x)— the probability that a given individual with characteristics x suffers from coronary heart desease</p>
<p>Here’s a scatter plot of the raw data. Each point is either 0 or 1 in functino of age. As you can see, it’s hard to discern a pattern directly.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p><strong>Data Description</strong>: Presence of chd as a function of age <span class="math inline">\(Y = \text{chd} \in \{0,1\}\)</span>, <span class="math inline">\(X = \text{age}\)</span></p>
</div>
<div class="fragment">
<p>We want to estimate <span class="math inline">\(p(x) = \E(Y|X = x) = \P(\text{chd} = 1|X = x)\)</span> for all <span class="math inline">\(x\)</span></p>
<div style="text-align: center;">
<p><img data-src="../images/logit1.png" style="width:50.0%"></p>
</div>
</div>
</section>
<section id="example-simple-idea" class="slide level2">
<h2>Example: Simple Idea</h2>
<aside class="notes">
<p>A simple first approach to understand the relationship.</p>
<p>We can group the x values by age class, then calculate the proportion of chd equals 1 in each class containing x.</p>
<p>Now we see something clearer! The proportion increases with age. But this approach is crude and doesn’t give us a smooth model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<ul>
<li class="fragment">Group the <span class="math inline">\(x\)</span> values by age class</li>
<li class="fragment">Calculate the proportion of <span class="math inline">\(chd = 1\)</span> in the class containing <span class="math inline">\(x\)</span></li>
</ul>
<div class="fragment">
<div style="text-align: center;">
<p><img data-src="../images/logit2.png" style="width:50.0%"></p>
</div>
</div>
</section>
<section id="example-glm-approach" class="slide level2">
<h2>Example: GLM Approach</h2>
<aside class="notes">
<p>The GLM approach gives us a smoother model.</p>
<p>We want to model p(x)—the probability that chd equals 1 given X equals x—as g-inverse of (beta_0 plus beta_1 times x).</p>
<p>This is a simple model with just an intercept and a slope. The age effect is captured by beta_1.</p>
<p>We need g-inverse to have values in [0,1] to ensure valid probabilities.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p><strong>Objective</strong>: We want to model <span class="math inline">\(p(x) = P(\text{chd} = 1|X = x)\)</span> by: <span class="math display">\[p(x) = g^{-1}(\beta_0 + \beta_1 x)\]</span></p>
</div>
<div class="fragment">
<p><strong>Constraint</strong>: We need <span class="math inline">\(g^{-1}\)</span> to have values in <span class="math inline">\([0, 1]\)</span></p>
</div>
</section>
<section id="example-the-logit-model" class="slide level2">
<h2>Example: The Logit Model</h2>
<aside class="notes">
<p>Let’s try the logit link—the most common choice.</p>
<p>g-inverse(t) equals e^t over (1 plus e^t), which means g(t) equals the natural log of t over (1 minus t)—the logit function.</p>
<p>Here are the results of g-inverse of (beta-hat_0 plus beta-hat_1 times x), obtained by maximum likelihood estimation. Notice how smooth the curve is, and how it respects the bounds—staying between 0 and 1.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<div style="font-size: 60%;">
<div class="square-def">
<p><span class="math display">\[g^{-1}(t) = \frac{e^t}{1 + e^t} \quad \text{i.e.} \quad g(t) = \ln\left(\frac{t}{1-t}\right) = \text{logit}(t)\]</span></p>
</div>
</div>
</div>
<div class="fragment">
<div class="columns">
<div class="column">
<div style="text-align: center;">
<p><img data-src="../images/logit3.png" style="width:100.0%"></p>
</div>
</div><div class="column">
<p><br>
<br>
Results of <span class="math inline">\(g^{-1}(\hat \beta_0 + \hat \beta_1 x)\)</span> obtained by MLE</p>
</div></div>
</div>
</section>
<section id="example-the-probit-model" class="slide level2">
<h2>Example: The Probit Model</h2>
<aside class="notes">
<p>What if we use a different link function?</p>
<p>If Phi is the CDF of a standard normal distribution, we take g-inverse(t) equals Phi(t).</p>
<p>Here are the results using the probit model with g-inverse of (beta-hat_0 plus beta-hat_1 times x), again obtained by MLE. Very similar to the logit model!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>If <span class="math inline">\(\Phi\)</span> is the CDF of a <span class="math inline">\(\mathcal{N}(0, 1)\)</span> distribution, we take <span style="background-color: lightblue;"><span class="math inline">\(g^{-1}(t) = \Phi(t)\)</span></span></p>
<div class="columns">
<div class="column">
<div style="text-align: center;">
<p><img data-src="../images/probit.png" style="width:100.0%"></p>
</div>
</div><div class="column">
<p><br>
<br>
Results of <span class="math inline">\(g^{-1}(\hat \beta_0 + \hat \beta_1 x)\)</span> obtained by MLE</p>
</div></div>
</div>
</section>
<section id="example-model-cloglog" class="slide level2">
<h2>Example: Model cloglog</h2>
<aside class="notes">
<p>Let’s try one more: the complementary log-log model.</p>
<p>g-inverse(t) equals 1 minus e to the negative e^t.</p>
<p>Here are the results. Notice this curve is not symmetric—it rises differently on the left versus the right compared to logit and probit.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[g^{-1}(t) = 1 - e^{-e^t}\]</span></p>
</div>
</div>
<div class="fragment">
<div class="columns">
<div class="column">
<div style="text-align: center;">
<p><img data-src="../images/cloglog.png" style="width:100.0%"></p>
</div>
</div><div class="column">
<p><br>
<br>
Results of <span class="math inline">\(g^{-1}(\hat \beta_0 + \hat \beta_1 x)\)</span> obtained by MLE</p>
</div></div>
</div>
</section>
<section id="example-comparison-of-the-three-models" class="slide level2">
<h2>Example: Comparison of the Three Models</h2>
<aside class="notes">
<p>Let’s compare all three models side by side.</p>
<p>Logit and probit give approximately the same result—the curves are nearly identical.</p>
<p>The cloglog differs slightly and is not symmetric. It approaches 1 much faster than it appraoches 0</p>
<p>Here they are overlaid. For this data, the choice doesn’t matter much, but in principle there are differences.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>logit and probit give <span style="background-color: yellow;">approximately the same result</span> cloglog differs slightly and is not “symmetric”</p>
<div style="text-align: center;">
<p><img data-src="../images/logitprobitloglog.png" style="width:50.0%"></p>
</div>
</div>
</section>
<section id="which-link-function-to-choose-for-binary-case" class="slide level2">
<h2>Which Link Function to Choose for Binary Case?</h2>
<aside class="notes">
<p>By default, we favor the logit model. This is the main choice for most applications.</p>
<p>However, there are exceptions. We might choose something else - such as the probit model, complementary log-log, or log-log - when there’s a good reason to do so.</p>
<p>In the next few slides, we’ll return to the three usual choices and justify why logit is typically preferred.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p><strong>Question</strong>: Which link function to choose in practice when <span class="math inline">\(Y\)</span> is binary?</p>
</div>
<div class="fragment">
<p><strong>Default choice</strong>: By default, we favor the <strong>logit model</strong></p>
</div>
<div class="fragment">
<p><strong>Exceptions</strong>: Unless there is a good reason to choose something else (probit model, complementary log-log, or log-log)</p>
</div>
<div class="fragment">
<p><strong>Next steps</strong>: We return to the 3 usual choices to justify this preference</p>
</div>
</section>
<section id="details-on-the-probit-model" class="slide level2">
<h2>Details on the Probit Model</h2>
<aside class="notes">
<p>The probit model has a specific theoretical justification. It’s appropriate when the binary variable Y given X equals x comes from thresholding a Gaussian latent variable Z of x.</p>
<p>Mathematically, Y given X equals x is the indicator that Z of x is greater than or equal to some threshold tau.</p>
<p>The key assumption is that Z of x follows a normal distribution with mean x transpose beta and variance sigma squared.</p>
<p>Let’s see what this implies for probabilities. If Phi is the cumulative distribution function of a standard normal distribution - that’s a normal with mean zero and variance one - then the probability that Y equals 1 given X equals x can be expressed as the probability that Z of x is at least tau. This equals Phi of the quantity x transpose beta minus tau, all divided by sigma.</p>
<p>This formulation shows how the probit model naturally arises from a latent variable framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>The probit model is justified when the binary variable <span class="math inline">\(Y|X = x\)</span> comes from thresholding a Gaussian latent variable <span class="math inline">\(Z(x)\)</span>:</p>
<div class="square-def">
<p><span class="math display">\[(Y|X = x) = \mathbf{1}_{Z(x) \geq \tau}\]</span></p>
</div>
<p>where <span style="background-color: lightblue;"><span class="math inline">\(Z(x) \sim \mathcal{N}(x^T\beta, \sigma^2)\)</span></span></p>
</div>
<div class="fragment">
<p>If <span class="math inline">\(\Phi\)</span> is the CDF of a <span class="math inline">\(\mathcal N(0,1)\)</span> <span class="math display">\[P(Y = 1|X = x) = P(Z(x) \geq \tau) = \Phi\left(\frac{x^T\beta - \tau}{\sigma}\right)\]</span></p>
</div>
</section>
<section id="examples-in-probit-model" class="slide level2">
<h2>Examples in Probit Model</h2>
<aside class="notes">
<p>Let me give you two concrete examples where the probit model makes intuitive sense.</p>
<p>First example: Y represents a purchase decision - whether someone buys a product or not. Here, Z of x quantifies the utility or satisfaction the person would get from the good. When this utility exceeds a threshold, they make the purchase.</p>
<p>Second example: Y is a declared psychological state, such as whether someone reports being happy or depressed. In this case, Z of x represents a latent, unobserved measure of personal satisfaction. The binary outcome we observe is just whether this latent satisfaction crosses a certain threshold.</p>
<p>In both cases, the idea of an underlying continuous variable being thresholded to create a binary outcome is very natural.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<ul>
<li class="fragment"><span class="math inline">\(Y\)</span> represents a purchase decision, and <span class="math inline">\(Z(x)\)</span> quantifies the utility of the good</li>
<li class="fragment"><span class="math inline">\(Y\)</span> is a declared psychological state (happiness, depression) and <span class="math inline">\(Z(x)\)</span> is a latent, unobserved measure of personal satisfaction</li>
</ul>
</section>
<section id="probit-vs-logit-current-trends" class="slide level2">
<h2>Probit vs Logit: Current Trends</h2>
<aside class="notes">
<p>The probit model remains relatively popular among econometricians. There’s a tradition of using it in economics research.</p>
<p>However, the general trend is that it’s increasingly being replaced by the logistic model across many fields.</p>
<p>Why is this happening? The logit model has many advantages that probit does not have. Let me highlight two key ones:</p>
<p>First, interpretation of results. The logit model allows us to work with odds ratios, which are very intuitive to interpret.</p>
<p>Second, explicit formulas. The logit model has closed-form expressions that make computation and interpretation easier.</p>
<p>From a theoretical perspective, there’s also good justification for this trend. The cumulative distribution function of the probit model is actually quite close to the CDF of the logit model, so we’re not losing much by switching.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p><strong>Econometricians</strong>: The <span style="background-color: yellow;">probit model</span> remains relatively popular among <span style="background-color: yellow;">econometricians</span>…</p>
</div>
<div class="fragment">
<p><strong>General trend</strong>: but it tends to be <span style="background-color: yellow;">replaced by the logistic model</span></p>
</div>
<div class="fragment">
<p><strong>Advantages of logit</strong>: The <span style="background-color: yellow;">logit model has many advantages</span> that probit does not have:</p>
<ul>
<li class="fragment">Interpretation of results</li>
<li class="fragment">Explicit formulas</li>
</ul>
</div>
<div class="fragment">
<p><strong>Theoretical justification</strong>: CDF of probit close to CDF of logit</p>
</div>
</section>
<section id="remarks-on-cloglog-model" class="slide level2">
<h2>Remarks on cloglog Model</h2>
<aside class="notes">
<p>Now let’s turn to the complementary log-log, or cloglog, model.</p>
<p>For cloglog, the link function g of t is the natural log of negative log of one minus t. The inverse link is therefore g inverse of t equals one minus e to the negative e to the t.</p>
<p>An important property of this link function is that it’s not symmetric. Specifically, g of t does not equal negative g of one minus t. What this means in practice is that p of x approaches zero slowly, but approaches one very rapidly.</p>
<p>If the opposite behavior is true in your data - if probabilities approach one slowly but zero rapidly - you should use the log-log model instead, where g of t equals negative natural log of negative natural log of t.</p>
<p>The cloglog model is particularly useful in survival models, such as Cox model where this kind of loglog appears naturally.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>The modeling approach is <span class="math inline">\(p(x) = g^{-1}(x^T\beta)\)</span> with</p>
<div class="square-def">
<p><span class="math display">\[g(t) = \ln(-\ln(1-t)) \quad \text{i.e.} \quad g^{-1}(t) = 1 - e^{-e^t}\]</span></p>
</div>
</div>
<div class="fragment">
<p>Not symmetric in the sense that <span style="background-color: lightblue;"><span class="math inline">\(g(t) \neq -g(1-t)\)</span></span>.</p>
<p><span class="math inline">\(p(x)\)</span> approaches <span class="math inline">\(0\)</span> slowly but <span class="math inline">\(1\)</span> very rapidly</p>
</div>
<div class="fragment">
<p>If the opposite is true: take <span class="math inline">\(g(t) = -\ln(-\ln(t))\)</span> (loglog model)</p>
</div>
<div class="fragment">
<p>Useful in <span style="background-color: yellow;">survival models</span> (e.g.&nbsp;Cox)</p>
</div>
</section>
<section id="details-on-the-logit-model" class="slide level2">
<h2>Details on the Logit Model</h2>
<aside class="notes">
<p>Let me give you three compelling reasons why the logit model is our preferred choice for binary regression.</p>
<p>First, it provides a highly valued interpretation tool: odds ratios. These allow us to communicate results in an intuitive way that’s meaningful across many fields, from medicine to social sciences to marketing.</p>
<p>Second, it’s more practical from a theoretical point of view. The mathematical properties make it easier to work with, and we have good theoretical foundations for why it arises naturally.</p>
<p>Third, the logit model is the natural model in many situations. As we’ll see in the next slide, it emerges automatically under common distributional assumptions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<ol type="1">
<li class="fragment"><p>Highly valued interpretation tool: odds-ratios.</p></li>
<li class="fragment"><p>More “practical” from a theoretical point of view.</p></li>
<li class="fragment"><p>Natural model in many situations.</p></li>
</ol>
</section>
<section id="theoretical-motivation-of-logit" class="slide level2">
<h2>Theoretical Motivation of Logit</h2>
<aside class="notes">
<p>Now let’s see a beautiful theoretical result that explains why logit is so natural.</p>
<p>We will show in exercises that there’s an important connection between the logit model and Gaussian distributions.</p>
<p>Here’s the setup: If the two groups of individuals associated with Y equals 0 and Y equals 1 have a Gaussian distribution of X with different means - that is, for m_0 not equal to m_1, we have X given Y equals 0 follows a normal distribution with mean m_0 and covariance Sigma, and X given Y equals 1 follows a normal distribution with mean m_1 and the same covariance Sigma - then the probability that Y equals 1 given X equals x automatically follows a logistic model.</p>
<p>This is a powerful result! It tells us that whenever we have two normally distributed groups that differ in their means but share the same covariance structure, the logit model emerges naturally.</p>
<p>And there’s more. The previous result remains true for any exponential family instead normal distributions. So this property of the logit model is quite general - it’s not limited to just Gaussian distributions.</p>
<p>This theoretical foundation helps explain why the logit model appears so frequently in practice.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>We will show in exercises that:</p>
<p><span style="background-color: orange;">If</span> the two groups of individuals associated with <span class="math inline">\(Y = 0\)</span> and <span class="math inline">\(Y = 1\)</span> have a Gaussian distribution of <span class="math inline">\(X\)</span> with different means, i.e.&nbsp;for <span class="math inline">\(m_0 \neq m_1\)</span>,</p>
<div class="square-def">
<p><span class="math inline">\(X|(Y = 0) \sim \mathcal N(m_0, \Sigma) \and X|(Y = 1) \sim \mathcal N(m_1, \Sigma)\)</span></p>
</div>
<p><span style="background-color: orange;">then</span> <span class="math inline">\(\mathbb P(Y = 1|X = x)\)</span> follows a logistic model.</p>
</div>
<div class="fragment">
<p>The previous result remains true for any distribution from the exponential family instead of <span class="math inline">\(\mathcal N\)</span>.</p>
</div>
</section>
<section id="summary-for-binary-variables" class="slide level2">
<h2>Summary for Binary Variables:</h2>
<aside class="notes">
<p>Let’s summarize our discussion about modeling binary variables.</p>
<p>If Y is a binary variable, then Y given X equals x follows a Bernoulli distribution with parameter p of x.</p>
<p>In a GLM model for Y, we set p of x equals g inverse of x transpose beta, where g is the link function. Now, which link function should we choose?</p>
<p>By default, we use the logit function, which is the most natural choice for all the reasons we’ve discussed: odds ratio interpretation, theoretical justification, and mathematical convenience.</p>
<p>Possibly, we might use probit if we have good reasons to justify it - for example, if there’s a clear latent variable story. But keep in mind that the results will typically be very similar to logit, so unless you have a compelling reason, logit is simpler.</p>
<p>We might use cloglog, or its mirror image loglog, if we have good reasons to justify it. The main reasons would be: first, strong asymmetry in p of x - probabilities that approach zero and one at very different rates - and second, a connection with a Cox model when dealing with discretized survival data.</p>
<p>In the following sections, we will focus on the logit model, since it’s the default choice and the most widely applicable.</p>
<p>This completes our journey through link function selection for binary outcomes. The key takeaway is: start with logit, and only consider alternatives when you have a specific, justifiable reason to do so.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>If <span class="math inline">\(Y\)</span> is a binary variable, <span style="background-color: lightblue;"><span class="math inline">\((Y|X = x) \sim \mathcal B(p(x))\)</span></span>.</p>
<p>In a GLM model for <span class="math inline">\(Y\)</span>, we set <span class="math inline">\(p(x) = g^{-1}(x^T\beta)\)</span> where <span class="math inline">\(g\)</span> is:</p>
<ul>
<li class="fragment"><p><span style="background-color: yellow;">by default the logit</span> function, which is the most natural;</p></li>
<li class="fragment"><p><span style="background-color: yellow;">possibly probit</span> if we have good reasons to justify it (but the results will be similar to logit);</p></li>
<li class="fragment"><p><span style="background-color: yellow;">cloglog (or loglog)</span> if we have good reasons to justify it (<span style="background-color: yellow;">strong asymmetry of <span class="math inline">\(p(x)\)</span></span>, connection with a Cox model).</p></li>
</ul>
</div>
<div class="fragment">
<p>In the following, we will <span style="background-color: yellow;">focus on the logit model</span>.</p>
</div>
</section>
<section id="outline" class="slide level2">
<h2>Outline</h2>
<aside class="notes">
<p>Now that we’ve established why the logit model is our preferred choice, let’s see how to work with it in practice.</p>
<p>We’ll cover four essential aspects: First, how to interpret the model and understand what the coefficients tell us. Second, how to estimate beta from a dataset. Third, how to evaluate the quality of our estimation. And fourth, how to exploit the model to make predictions and perform classification.</p>
<p>Let’s begin with model interpretation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<ul>
<li class="fragment">interpret the model,</li>
<li class="fragment">estimate <span class="math inline">\(\beta\)</span> from a dataset,</li>
<li class="fragment">evaluate the quality of estimation,</li>
<li class="fragment">exploit it to make predictions/classification.</li>
</ul>
</section></section>
<section>
<section id="model-interpretation" class="title-slide slide level1 center">
<h1>Model Interpretation</h1>

</section>
<section id="interpretation-of-the-logistic-model" class="slide level2">
<h2>Interpretation of the Logistic Model</h2>
<aside class="notes">
<p>Let’s start with the mathematical form of the logistic model.</p>
<p>If x is a vector with p components - x superscript 1 through x superscript p - then our model is:</p>
<p>p of x equals logit inverse of x transpose beta, which equals e to the x transpose beta, divided by 1 plus e to the x transpose beta.</p>
<p>What does this tell us about how each variable affects the probability?</p>
<p>First key point: p of x is increasing with x^{(j)} if beta j is positive, and decreasing otherwise. So the sign of the coefficient tells us the direction of the effect.</p>
<p>Second key point: The larger the absolute value of beta j, the stronger the discriminatory power of regressor X j. In other words, when the coefficient has a large magnitude, a small variation in x j can cause a large variation in p of x.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<p>If <span class="math inline">\(x=(x^{(1)}, \dots, x^{(p)}) \in \mathbb R^{p \times 1}\)</span></p>
<div class="square-def">
<p><span class="math display">\[p(x) = \text{logit}^{-1}(x^T\beta) = \frac{e^{x^T\beta}}{1 + e^{x^T\beta}}\]</span></p>
</div>
<ul>
<li class="fragment"><p><span class="math inline">\(x^{(j)} \to p(x)\)</span> is increasing if <span class="math inline">\(\beta_j &gt; 0\)</span>, decreasing otherwise.</p></li>
<li class="fragment"><p>The larger <span class="math inline">\(|\beta_j|\)</span> is, the stronger the discriminatory power of regressor <span class="math inline">\(X^{(j)}\)</span> (a small variation in <span class="math inline">\(x^{(j)}\)</span> can cause a large variation in <span class="math inline">\(p(x)\)</span>).</p></li>
</ul>
</section>
<section id="shape-of-logit-function" class="slide level2">
<h2>Shape of logit function</h2>
<aside class="notes">
<p>Let me show you what this relationship looks like visually.</p>
<p>The shape of the function that maps x superscript j to p of x has this characteristic S-curve, or sigmoid shape. You can see how the probability transitions smoothly from near zero to near one as the predictor increases. The steepness of this S-curve in the middle region is determined by the magnitude of beta j - larger coefficients create steeper transitions.</p>
<p>This S-shaped relationship is one of the appealing features of the logistic model - it naturally constrains probabilities to lie between zero and one, and it has this smooth, interpretable transition region.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<div style="text-align: center;">
<p><img data-src="../images/shape_logit.png" style="width:40.0%"></p>
</div>
<p>shape of <span class="math inline">\(x^{(j)} \to p(x)\)</span></p>
</div>
</section>
<section id="example-bmi-study-french-imc" class="slide level2">
<h2>Example: BMI Study (French: IMC)</h2>
<aside class="notes">
<p>Let’s look at a concrete example to make this more tangible. This is a BMI study with French data - BMI is called IMC in French.</p>
<p>For each of 5,300 patients, we observe several variables:</p>
<p>Our outcome variable Y is binary: it equals 1 if BMI is greater than 35, and 0 otherwise. So we’re trying to predict obesity.</p>
<p>Our predictor variables include: AGE in years, DBP which is diastolic blood pressure - that’s the low pressure measurement, SEXE indicating male or female, ACTIV which equals 1 if the person engages in intense sports activity and 0 otherwise, WALK which equals 1 if they walk or cycle to work and 0 otherwise, and MARITAL which is marital status with 6 categories: married, widowed, divorced, separated, single, or cohabiting.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<p>For each of the 5300 patients, we observe:</p>
<ul>
<li class="fragment"><span style="background-color: yellow;"><span class="math inline">\(Y\)</span>: 1 if BMI &gt; 35</span>, 0 otherwise</li>
<li class="fragment">AGE</li>
<li class="fragment">DBP: low pressure (diastolic)</li>
<li class="fragment">SEXE: male or female</li>
<li class="fragment">ACTIV: 1 if intense sports activity, 0 otherwise</li>
<li class="fragment">WALK: 1 if walking or cycling to work, 0 otherwise</li>
<li class="fragment">MARITAL: marital status (6 categories: married, widowed, divorced, separated, single or cohabiting)</li>
</ul>
</section>
<section id="model-definition" class="slide level2">
<h2>Model Definition</h2>
<aside class="notes">
<p>Our goal is to model the probability that Y equals 1 given X, where X groups all the predictor variables we just mentioned, excluding Y of course.</p>
<p>In R, implementing this is straightforward. We use the glm function - that’s generalized linear model - with the family equals binomial option. This tells R we’re doing logistic regression.</p>
<p>The syntax would be: glm of Y tilde AGE plus DBP plus SEXE plus ACTIV plus WALK plus MARITAL, with family equals binomial.</p>
<p>The tilde notation means “is modeled by” and the plus signs indicate we’re including all these variables as predictors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>We seek to model <span class="math inline">\(P(Y = 1|X)\)</span> where <span class="math inline">\(X\)</span> groups the previous variables (excluding <span class="math inline">\(Y\)</span>).</p>
</div>
<div class="fragment">
<p>In R, we use the <code>glm</code> function with the <code>family=binomial</code> option.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a><span class="fu">glm</span>(Y <span class="sc">~</span> AGE <span class="sc">+</span> DBP <span class="sc">+</span> SEXE <span class="sc">+</span> ACTIV <span class="sc">+</span> WALK <span class="sc">+</span> MARITAL, <span class="at">family=</span>binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-results" class="slide level2">
<h2>Model Results</h2>
<aside class="notes">
<p>Now let’s look at what the model produces.</p>
<p>The output gives us estimated coefficients, as in linear regression</p>
<p>Looking at the significant variables - those marked with asterisks - we see several interesting patterns:</p>
<p>DBP, diastolic blood pressure, has a positive coefficient and is highly significant. Higher blood pressure is associated with higher probability of obesity.</p>
<p>Being female - SEXE FEMME - has a positive significant coefficient, indicating women in this sample have higher probability of high BMI.</p>
<p>WALK1 and ACTIV1 both have negative coefficients and are highly significant. This makes intuitive sense: people who walk or cycle to work, and people who engage in intense physical activity, have lower probability of high BMI.</p>
<p>AGE appears not to be significant in this simple linear form.</p>
<p>Looking at the marital status variables - MARITAL 2 through 6 - none of them are statistically significant. This suggests we want to remove the MARITAL variable from the model to simplify it.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<div style="font-size: 50%;">
<table class="caption-top">
<colgroup>
<col style="width: 18%">
<col style="width: 15%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 18%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Estimate</th>
<th>Std. Error</th>
<th>z value</th>
<th>Pr(&gt;</th>
<th>z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td>-2.810240</td>
<td>0.294316</td>
<td>-9.548</td>
<td>&lt; 2e-16</td>
<td>***</td>
</tr>
<tr class="even">
<td>AGE</td>
<td>-0.004407</td>
<td>0.002717</td>
<td>-1.622</td>
<td>0.105</td>
<td></td>
</tr>
<tr class="odd">
<td>DBP</td>
<td>0.017581</td>
<td>0.003283</td>
<td>5.356</td>
<td>8.53e-08</td>
<td>***</td>
</tr>
<tr class="even">
<td>SEXEFEMME</td>
<td>0.544916</td>
<td>0.081261</td>
<td>6.706</td>
<td>2.00e-11</td>
<td>***</td>
</tr>
<tr class="odd">
<td>WALK1</td>
<td>-0.409344</td>
<td>0.095972</td>
<td>-4.265</td>
<td>2.00e-05</td>
<td>***</td>
</tr>
<tr class="even">
<td>ACTIV1</td>
<td>-0.789734</td>
<td>0.126653</td>
<td>-6.235</td>
<td>4.51e-10</td>
<td>***</td>
</tr>
<tr class="odd">
<td>MARITAL2</td>
<td>0.070132</td>
<td>0.149638</td>
<td>0.469</td>
<td>0.639</td>
<td></td>
</tr>
<tr class="even">
<td>MARITAL3</td>
<td>-0.071318</td>
<td>0.127510</td>
<td>-0.559</td>
<td>0.576</td>
<td></td>
</tr>
<tr class="odd">
<td>MARITAL4</td>
<td>0.188228</td>
<td>0.206598</td>
<td>0.911</td>
<td>0.362</td>
<td></td>
</tr>
<tr class="even">
<td>MARITAL5</td>
<td>0.070613</td>
<td>0.115928</td>
<td>0.609</td>
<td>0.542</td>
<td></td>
</tr>
<tr class="odd">
<td>MARITAL6</td>
<td>-0.150165</td>
<td>0.157687</td>
<td>-0.952</td>
<td>0.341</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="fragment">
<p>The interpretation is similar to that of a linear regression model.</p>
</div>
<div class="fragment">
<p>We want to remove the MARITAL variable from the model.</p>
</div>
</section>
<section id="model-results-with-age2" class="slide level2">
<h2>Model Results with <span class="math inline">\(AGE^2\)</span></h2>
<aside class="notes">
<p>Perhaps AGE has a non-linear effect. Let’s try adding AGE squared to the model.</p>
<p>In R, we write: glm of Y tilde AGE plus I of AGE squared</p>
<p>Now look at what happens.</p>
<p>Both AGE and AGE squared are now highly significant! The positive coefficient on AGE and negative coefficient on AGE squared suggests an inverted U-shape relationship: the probability of high BMI increases with age initially, then decreases at older ages.</p>
<p>All our other key variables remain significant with similar interpretations.</p>
<p>For someone for which WALK1 equals 0 and ACTIV1 equals 0 - so they don’t walk to work and don’t do intense sports - the probability that Y equals 1 given their age and blood pressure is: logit inverse of negative 3.95 plus 0.064 times AGE minus 0.00068 times AGE squared plus 0.0122 times DBP.</p>
<p>Now, for someone for which WALK1 equals 0 and ACTIV1 equals 1 - they do engage in intense sports activity - we get the same formula but we subtract 0.657. That’s the coefficient of ACTIV1 in red. This person has a lower probability of high BMI, all else being equal, and we can quantify exactly how much lower.</p>
<p>This demonstrates how we can use the fitted model to compute predicted probabilities for individuals with different covariate profiles.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a></a><span class="fu">glm</span>(Y <span class="sc">~</span> AGE <span class="sc">+</span> <span class="fu">I</span>(AGE<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> DBP <span class="sc">+</span> SEXE <span class="sc">+</span> WALK <span class="sc">+</span> ACTIV, <span class="at">family=</span>binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Gives</p>
</div>
<div class="fragment">
<div style="font-size: 50%;">
<table class="caption-top">
<colgroup>
<col style="width: 17%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 17%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Estimate</th>
<th>Std. Error</th>
<th>z value</th>
<th>Pr(&gt;</th>
<th>z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td>-3.9564361</td>
<td>0.3155529</td>
<td>-12.538</td>
<td>&lt; 2e-16</td>
<td>***</td>
</tr>
<tr class="even">
<td>AGE</td>
<td>0.0640837</td>
<td>0.0123960</td>
<td>5.170</td>
<td>2.34e-07</td>
<td>***</td>
</tr>
<tr class="odd">
<td>I(AGE^2)</td>
<td>-0.0006758</td>
<td>0.0001260</td>
<td>-5.364</td>
<td>8.14e-08</td>
<td>***</td>
</tr>
<tr class="even">
<td>DBP</td>
<td>0.0121546</td>
<td>0.0033775</td>
<td>3.599</td>
<td>0.00032</td>
<td>***</td>
</tr>
<tr class="odd">
<td>SEXEFEMME</td>
<td>0.5155651</td>
<td>0.0776229</td>
<td>6.642</td>
<td>3.10e-11</td>
<td>***</td>
</tr>
<tr class="even">
<td>WALK1</td>
<td>-0.4042257</td>
<td>0.0913195</td>
<td>-4.426</td>
<td>9.58e-06</td>
<td>***</td>
</tr>
<tr class="odd">
<td>ACTIV1</td>
<td>-0.6573558</td>
<td>0.1150226</td>
<td>-5.715</td>
<td>1.10e-08</td>
<td>***</td>
</tr>
</tbody>
</table>
</div>
<p>For someone for which WALK1=0 and <span style="background-color: yellow;">ACTIV1=0</span>:</p>
<div style="font-size: 50%;">
<p><span class="math inline">\(P(Y = 1|\text{AGE}, \text{DBP}) = \text{logit}^{-1}(-3.95 + 0.064 \times \text{AGE} - 0.00068 \times \text{AGE}^2 + 0.0122 \times \text{DBP})\)</span></p>
</div>
</div>
<div class="fragment">
<p>For someone for which WALK1=0 and <span style="background-color: yellow;">ACTIV1=1</span>:</p>
<div style="font-size: 50%;">
<p><span class="math inline">\(P(Y = 1|\text{AGE}, \text{DBP}) = \text{logit}^{-1}(-3.95 + 0.064 \times \text{AGE} - 0.00068 \times \text{AGE}^2 + 0.0122 \times \text{DBP} \color{red}{ - 0.657})\)</span></p>
</div>
</div>
</section>
<section id="odds" class="slide level2">
<h2>Odds</h2>
<aside class="notes">
<p>Let’s look at how odds relate to probability. When we know the probability pp of an event, its odds are simply p/(1−p)p/(1−p). For example, if the probability of winning is 0.75, then the odds are 0.75/0.25=30.75/0.25=3. That means the event is three times as likely to happen than not to happen.</p>
<p>​</p>
<p>In betting, when you hear “odds 3 to 1,” it means for every 3 people who bet on event A, there’s 1 person betting against it. That also means, if you pick a random bettor, there’s a 3 out of 4 chance they chose A, giving you a probability p=3/4p=3/4 and for not-A, 1/41/4.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="square-def">
<p><span class="math display">\[\text{odds} = \frac{p}{1-p}\]</span></p>
</div>
<div class="fragment">
<p><strong>Betting interpretation</strong> for example, <span class="math inline">\(3\)</span> to <span class="math inline">\(1\)</span> means that for <span class="math inline">\(3\)</span> people betting on <span class="math inline">\(A\)</span>, <span class="math inline">\(1\)</span> person bets on <span class="math inline">\(B\)</span>.</p>
</div>
<div class="fragment">
<p>So a randomly chosen bettor has a probability of <span class="math inline">\(p=3/4\)</span> of betting on <span class="math inline">\(A\)</span> and <span class="math inline">\(1-p=1/4\)</span> on betting on <span class="math inline">\(B\)</span></p>
</div>
</section>
<section id="odds-given-xx" class="slide level2">
<h2>Odds given <span class="math inline">\(X=x\)</span></h2>
<aside class="notes">
<p>​</p>
<p>Just like before, if we consider the probability of an event given some condition—say, the odds of Y=1Y=1 given X=xX=x—we use p(x)p(x) to denote the probability. The odds in this case are odds(x)=p(x)1−p(x)odds(x)=1−p(x)p(x), where p(x)=P(Y=1∣X=x)p(x)=P(Y=1∣X=x) If <span class="math inline">\(p\)</span> is the probability of an event <span class="math inline">\(A\)</span>, then its odds are:</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>Similarly, the odds of obtaining <span class="math inline">\(Y = 1\)</span> given <span class="math inline">\(X = x\)</span> is:</p>
<div class="square-def">
<p><span class="math display">\[\text{odds}(x) = \frac{p(x)}{1 - p(x)}\]</span></p>
</div>
</div>
<div class="fragment">
<p>where <span class="math inline">\(p(x) = P(Y = 1|X = x)\)</span>.</p>
</div>
</section>
<section id="odds-ratio" class="slide level2">
<h2>Odds Ratio</h2>
<aside class="notes">
<p>Now let’s talk about the odds ratio, which compares odds between two different individuals or groups.</p>
<p>If we have two people with characteristics x1x1 and x2x2, the odds ratio tells us how the odds compare between them. It’s calculated as OR(x1,x2)=odds(x1)odds(x2)OR(x1,x2)=odds(x2)odds(x1), which expands to that double fraction you see on the slide.</p>
<p>Here’s something really important though: don’t confuse odds ratio with probability ratio. They’re not the same thing.</p>
<p>The odds ratio is a ratio of odds, not probabilities. So if someone has odds of 3 and another person has odds of 1.5, the odds ratio is 2. But that doesn’t mean one person has twice the probability of the other.</p>
<p>There’s only one exception to watch out for: when both probabilities are very small—say, less than 0.1. In that case, 1−p(x1)1−p(x1) is approximately 1, and 1−p(x2)1−p(x2) is also approximately 1. So the denominators basically cancel out, and the odds ratio becomes pretty close to the probability ratio. But this only works for rare events.</p>
<p>Otherwise, always remember: odds ratios and probability ratios are different beasts, so don’t treat them the same way.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>If two individuals have characteristics <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> respectively, we call the odds ratio between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>:</p>
<p><span class="math display">\[OR(x_1, x_2) = \frac{\text{odds}(x_1)}{\text{odds}(x_2)} = \frac{\frac{p(x_1)}{1-p(x_1)}}{\frac{p(x_2)}{1-p(x_2)}}\]</span></p>
</div>
<div class="fragment">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Warning</strong></p>
</div>
<div class="callout-content">
<p><span style="background-color: orange;"><strong>DO NOT CONFUSE ODDS RATIO WITH PROBABILITY RATIO</strong></span></p>
<p>Only possible exception: if <span class="math inline">\(p(x_1)\)</span> and <span class="math inline">\(p(x_2)\)</span> are very small because then <span class="math inline">\(1 - p(x_1) \approx 1\)</span> and <span class="math inline">\(1 - p(x_2) \approx 1\)</span>, so that <span class="math inline">\(OR(x_1, x_2) \approx p(x_1)/p(x_2)\)</span></p>
</div>
</div>
</div>
</div>
</section>
<section id="link-with-proba.-ratio" class="slide level2">
<h2>Link with Proba. Ratio</h2>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>However, it remains that:</p>
<p><span class="math display">\[\begin{aligned}
OR(x_1, x_2) &gt; 1 &amp;\Leftrightarrow \frac{p(x_1)}{p(x_2)} &gt; 1\\
OR(x_1, x_2) &lt; 1 &amp;\Leftrightarrow \frac{p(x_1)}{p(x_2)} &lt; 1\\
OR(x_1, x_2) = 1 &amp;\Leftrightarrow \frac{p(x_1)}{p(x_2)} = 1
\end{aligned}\]</span></p>
</div>
</section>
<section id="other-property-of-odds-ratio" class="slide level2">
<h2>Other Property of Odds Ratio</h2>
<div class="fragment">
<p><span class="math inline">\(OR(x_1, x_2)\)</span> accentuates the differences compared to <span class="math inline">\(p(x_1)/p(x_2)\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
OR(x_1, x_2) &gt; \frac{p(x_1)}{p(x_2)} &amp;\text{ when } OR(x_1, x_2) &gt; 1\\
OR(x_1, x_2) &lt; \frac{p(x_1)}{p(x_2)} &amp;\text{ when } OR(x_1, x_2) &lt; 1
\end{aligned}\]</span></p>
</div>
</section>
<section id="examples-using-odds-ratios" class="slide level2">
<h2>Examples Using Odds Ratios</h2>
<div class="fragment">
<p>A logistic regression is most often used to compare the <span style="background-color: lightgreen;">behavior of two individuals</span> with respect to <span style="background-color: lightblue;">the variable of interest</span>.</p>
</div>
<div class="fragment">
<p>Examples:</p>
<ul>
<li class="fragment"><span style="background-color: lightgreen;">probability of purchase</span> depending on whether or not one has been the <span style="background-color: lightblue;">subject of a personalized promotion</span>;</li>
<li class="fragment">for a given vehicle, <span style="background-color: lightgreen;">probability of experiencing a breakdown</span> <span style="background-color: lightblue;">according to age</span>;</li>
<li class="fragment"><span style="background-color: lightgreen;">probability of recovery</span> according to the <span style="background-color: lightblue;">treatment used</span>;</li>
</ul>
</div>
</section>
<section id="odds-ratio-in-logistic-regression" class="slide level2">
<h2>Odds Ratio in Logistic Regression</h2>
<div class="fragment">
<p>It holds that <span style="background-color: lightblue;"><span class="math inline">\(\text{odds}(x) = \frac{p(x)}{1 - p(x)} = \exp(x^T \beta)\)</span></span></p>
<p>Hence,</p>
<div class="square-def">
<p><span class="math inline">\(OR(x_1, x_2) = \frac{\text{odds}(x_1)}{\text{odds}(x_2)} = \exp((x_1 - x_2)^T \beta)\)</span></p>
</div>
</div>
<div class="fragment">
<p>If the two individuals differ only by regressor <span class="math inline">\(j\)</span>, then</p>
<p><span class="math inline">\(OR(x_1, x_2) = \exp(\beta_j (x_1^{(j)} - x_2^{(j)}))\)</span></p>
</div>
<div class="fragment">
<p>If regressor <span class="math inline">\(j\)</span> is binary (<span class="math inline">\(x_1^{(j)} = 1\)</span> while <span class="math inline">\(x_2^{(j)} = 0\)</span>):</p>
<p><span class="math inline">\(OR(x_1, x_2) = \exp(\beta_j)\)</span></p>
</div>
</section>
<section id="key-summary-statement" class="slide level2">
<h2>Key Summary Statement</h2>
<div class="fragment">
<p>In a logistic regression model, <span class="math inline">\(\beta_j\)</span> is interpreted as the logarithm of the odds-ratio between two individuals differing by a quantity of <span class="math inline">\(1\)</span> on regressor <span class="math inline">\(j\)</span>, all else being equal.</p>
</div>
<div class="fragment">
<p><strong>In brief:</strong> <span style="background-color: yellow;"><span class="math inline">\(\exp(\beta_j) = OR(x^{(j)} + 1, x^{(j)})\)</span></span></p>
<p>If regressor <span class="math inline">\(j\)</span> is binary (absence or presence of a certain characteristic):</p>
</div>
<div class="fragment">
<p><span class="math inline">\(\exp(\beta_j)\)</span> is simply the OR between the <span style="background-color: yellow;">presence or absence</span> of this characteristic, all else being equal.</p>
</div>
</section>
<section id="example-1-intense-sports-activity" class="slide level2">
<h2>Example 1: Intense Sports Activity</h2>
<div class="fragment">
<div style="font-size: 50%;">
<table class="caption-top">
<colgroup>
<col style="width: 17%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 17%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Estimate</th>
<th>Std. Error</th>
<th>z value</th>
<th>Pr(&gt;</th>
<th>z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td>-3.9564361</td>
<td>0.3155529</td>
<td>-12.538</td>
<td>&lt; 2e-16</td>
<td>***</td>
</tr>
<tr class="even">
<td>AGE</td>
<td>0.0640837</td>
<td>0.0123960</td>
<td>5.170</td>
<td>2.34e-07</td>
<td>***</td>
</tr>
<tr class="odd">
<td>I(AGE^2)</td>
<td>-0.0006758</td>
<td>0.0001260</td>
<td>-5.364</td>
<td>8.14e-08</td>
<td>***</td>
</tr>
<tr class="even">
<td>DBP</td>
<td>0.0121546</td>
<td>0.0033775</td>
<td>3.599</td>
<td>0.00032</td>
<td>***</td>
</tr>
<tr class="odd">
<td>SEXEFEMME</td>
<td>0.5155651</td>
<td>0.0776229</td>
<td>6.642</td>
<td>3.10e-11</td>
<td>***</td>
</tr>
<tr class="even">
<td>WALK1</td>
<td>-0.4042257</td>
<td>0.0913195</td>
<td>-4.426</td>
<td>9.58e-06</td>
<td>***</td>
</tr>
<tr class="odd">
<td>ACTIV1</td>
<td>-0.6573558</td>
<td>0.1150226</td>
<td>-5.715</td>
<td>1.10e-08</td>
<td>***</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="fragment">
<p>The Odds Ratio corresponding to practicing or not practicing intense sports activity is, all else being equal:</p>
</div>
<div class="fragment">
<p><span class="math inline">\(\exp(-0.657) \approx 0.52\)</span></p>
</div>
<div class="fragment">
<p>The odds of obesity occurrence therefore decrease by half for individuals practicing intense sports activity.</p>
<p><strong>(The odds, not the probability!)</strong></p>
</div>
</section>
<section id="example-2-diastolic-pressure" class="slide level2">
<h2>Example 2: Diastolic Pressure</h2>
<div style="font-size: 50%;">
<table class="caption-top">
<colgroup>
<col style="width: 17%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 17%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Estimate</th>
<th>Std. Error</th>
<th>z value</th>
<th>Pr(&gt;</th>
<th>z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td>-3.9564361</td>
<td>0.3155529</td>
<td>-12.538</td>
<td>&lt; 2e-16</td>
<td>***</td>
</tr>
<tr class="even">
<td>AGE</td>
<td>0.0640837</td>
<td>0.0123960</td>
<td>5.170</td>
<td>2.34e-07</td>
<td>***</td>
</tr>
<tr class="odd">
<td>I(AGE^2)</td>
<td>-0.0006758</td>
<td>0.0001260</td>
<td>-5.364</td>
<td>8.14e-08</td>
<td>***</td>
</tr>
<tr class="even">
<td>DBP</td>
<td>0.0121546</td>
<td>0.0033775</td>
<td>3.599</td>
<td>0.00032</td>
<td>***</td>
</tr>
<tr class="odd">
<td>SEXEFEMME</td>
<td>0.5155651</td>
<td>0.0776229</td>
<td>6.642</td>
<td>3.10e-11</td>
<td>***</td>
</tr>
<tr class="even">
<td>WALK1</td>
<td>-0.4042257</td>
<td>0.0913195</td>
<td>-4.426</td>
<td>9.58e-06</td>
<td>***</td>
</tr>
<tr class="odd">
<td>ACTIV1</td>
<td>-0.6573558</td>
<td>0.1150226</td>
<td>-5.715</td>
<td>1.10e-08</td>
<td>***</td>
</tr>
</tbody>
</table>
</div>
<p>The OR for a diastolic pressure difference of <span class="math inline">\(+20\)</span> is:</p>
<div class="fragment">
<p><span class="math inline">\(\exp(0.0121546 \times 20) \approx 1.28\)</span></p>
</div>
<div class="fragment">
<p>The odds of obesity occurrence therefore increase by <span class="math inline">\(28\%\)</span>.</p>
</div>
</section></section>
<section>
<section id="estimation-of-the-parameters" class="title-slide slide level1 center">
<h1>EStimation of the Parameters</h1>

</section>
<section id="the-framework" class="slide level2">
<h2>The Framework</h2>
<div class="fragment">
<p>We observe <span class="math inline">\(n\)</span> i.i.d. realizations <span class="math inline">\((Y_i, X_i)\)</span> where <span class="math inline">\(Y_i \in \{0, 1\}\)</span> and <span class="math inline">\(X_i \in \mathbb{R}^p\)</span>.</p>
</div>
<div class="fragment">
<p>We denote <span class="math inline">\(p(x_i) = P(Y_i = 1|X_i = x_i)\)</span>.</p>
</div>
</section>
<section id="the-logistic-model" class="slide level2">
<h2>The Logistic Model</h2>
<div class="fragment">
<p>We assume the logistic model: for all <span class="math inline">\(i\)</span>,</p>
<div class="square-def">
<p><span class="math display">\[p(x_i) = \text{logit}^{-1}(x_i^T \beta) = \frac{e^{x_i^T \beta}}{1 + e^{x_i^T \beta}}\]</span></p>
</div>
</div>
<div class="fragment">
<p>where <span class="math inline">\(\beta = (\beta_1, \ldots, \beta_p)^T\)</span> and <span class="math inline">\(x_i^T \beta = \beta_1 x_i^{(1)} + \cdots + \beta_p x_i^{(p)}\)</span>.</p>
</div>
</section>
<section id="parameter-estimation" class="slide level2">
<h2>Parameter Estimation</h2>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[p(x_i) = \text{logit}^{-1}(x_i^T \beta) = \frac{e^{x_i^T \beta}}{1 + e^{x_i^T \beta}}\]</span></p>
</div>
<p>We will estimate <span class="math inline">\(\beta\)</span> by <span style="background-color: yellow;">maximizing the likelihood</span>.</p>
</div>
<div class="fragment">
<p>We will denote <span style="background-color: lightblue;"><span class="math inline">\(p_\beta(x_i)\)</span></span> to emphasize the dependence of <span style="background-color: lightblue;"><span class="math inline">\(p(x_i)\)</span></span> on <span class="math inline">\(\beta\)</span>.</p>
</div>
</section>
<section id="likelihood-calculation" class="slide level2">
<h2>Likelihood Calculation</h2>
<div class="fragment">
<p>For all <span class="math inline">\(i\)</span>, <span class="math inline">\(Y_i|(X_i = x_i)\)</span> follows the distribution <span class="math inline">\(B(p_\beta(x_i))\)</span>. Therefore</p>
<div style="font-size: 80%;">
<div class="square-def">
<p><span class="math display">\[P(Y_i = y_i|X_i = x_i) = p_\beta(x_i)^{y_i}(1 - p_\beta(x_i))^{1-y_i}\]</span></p>
</div>
</div>
</div>
<div class="fragment">
<p>for all <span class="math inline">\(y_i \in \{0, 1\}\)</span>.</p>
</div>
</section>
<section id="likelihood" class="slide level2">
<h2>Likelihood</h2>
<div class="fragment">
<p>By independence, we obtain the likelihood</p>
<div class="square-def">
<p><span class="math display">\[\ell(\beta, y_1, \ldots, y_n, x_1, \ldots, x_n) = \prod_{i=1}^n p_\beta(x_i)^{y_i}(1 - p_\beta(x_i))^{1-y_i}\]</span></p>
</div>
</div>
</section>
<section id="log-likelihood" class="slide level2">
<h2>Log-Likelihood</h2>
<div class="fragment">
<p>Taking the log and replacing <span class="math inline">\(p(x_i)\)</span> by its expression, we obtain the log-likelihood:</p>
<div style="font-size: 80%;">
<div class="square-def">
<p><span class="math display">\[\begin{aligned}
L(\beta, y_1, \ldots, y_n, x_1, \ldots, x_n) &amp;= \ln(\ell) \\
&amp;=\sum_{i=1}^n \left[y_i x_i^T \beta - \ln(1 + e^{x_i^T \beta})\right]
\end{aligned}\]</span></p>
</div>
</div>
</div>
</section>
<section id="mle-calculation" class="slide level2">
<h2>MLE Calculation</h2>
<div class="fragment">
<p>The MLE <span class="math inline">\(\hat{\beta}\)</span>, if it exists, cancels the gradient of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(\beta\)</span>. This gradient equals</p>
<div class="square-def">
<p><span class="math display">\[\frac{\partial L}{\partial \beta} = \sum_{i=1}^n x_i \left(y_i - \frac{e^{x_i^T \beta}}{1 + e^{x_i^T \beta}}\right)\]</span></p>
</div>
<p>We therefore need to solve a system of <span class="math inline">\(p\)</span> equations with <span class="math inline">\(p\)</span> unknowns.</p>
</div>
<div class="fragment">
<p>But the solution is not explicit: we resort to <span style="background-color: yellow;">numerical methods</span> (Newto-Raphso algo)</p>
</div>
</section>
<section id="remarks" class="slide level2">
<h2>Remarks</h2>
<div class="fragment">
<p>This is a classic situation when using advanced statistical models: we often <span style="background-color: yellow;">resort to optimization algorithms</span>.</p>
</div>
<div class="fragment">
<p>Does the solution exist? Is it unique?</p>
</div>
</section>
<section id="mle-uniqueness" class="slide level2">
<h2>MLE Uniqueness</h2>
<div class="fragment">
<p>Let <span class="math inline">\(X\)</span> be the design matrix <span class="math inline">\((X^{(1)}, \dots, X^{(p)}) \in \mathbb R^{n \times p}\)</span></p>
</div>
<div class="fragment">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Proposition</strong></p>
</div>
<div class="callout-content">
<p>If <span class="math inline">\(\text{rank}(X) = p\)</span>, then the MLE, if it exists, is unique.</p>
</div>
</div>
</div>
</div>
</section>
<section id="proof-of-mle-uniqueness" class="slide level2">
<h2>Proof of MLE Uniqueness</h2>
<div class="fragment">
<p>It suffices to show that <span class="math inline">\(L\)</span> is strictly concave in <span class="math inline">\(\beta\)</span>.</p>
</div>
<div class="fragment">
<p>Hessian Matrix of <span class="math inline">\(L\)</span>:</p>
<p><span class="math display">\[\frac{\partial^2 L}{\partial \beta^2} = -\sum_{i=1}^n p_\beta(x_i)(1 - p_\beta(x_i)) x_i x_i^T\]</span></p>
</div>
</section>
<section id="hessian-properties" class="slide level2">
<h2>Hessian Properties</h2>
<div class="fragment">
<p>It is negative semi-definite. Moreover, for all <span class="math inline">\(u \in \mathbb{R}^p\)</span>,</p>
<p><span class="math display">\[\begin{aligned}
u^T \frac{\partial^2 L}{\partial \beta^2} u = 0 &amp;\Leftrightarrow u^T x_i x_i^T u = 0 \text{ for all } i\\
&amp;\Leftrightarrow u^T x_i = 0 \text{ for all } i\\
&amp;\Leftrightarrow Xu = 0\\
&amp;\Leftrightarrow u = 0
\end{aligned}\]</span></p>
<p>since <span class="math inline">\(\text{rank}(X) = p\)</span>.</p>
</div>
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<div class="fragment">
<p>Thus, for all <span class="math inline">\(u \neq 0\)</span>,</p>
<div class="square-def">
<p><span class="math display">\[u^T \frac{\partial^2 L}{\partial \beta^2} u &lt; 0\]</span></p>
</div>
<p>The Hessian matrix is negative definite and therefore <span class="math inline">\(L\)</span> is strictly concave,</p>
<p>The MLE is unique</p>
</div>
</section>
<section id="about-mle-existence" class="slide level2">
<h2>About MLE Existence</h2>
<div class="fragment">
<p>Although <span class="math inline">\(L\)</span> is strictly concave, its <span style="background-color: orange;">maximum can occur at infinity</span> (think of the <span class="math inline">\(\ln\)</span> function), in which case <span class="math inline">\(\hat{\beta}\)</span> does not exist.</p>
</div>
<div class="fragment">
<p>This occurs if there is <span style="background-color: yellow;">non-overlap</span>, i.e., separation by a hyperplane of the <span class="math inline">\(x_i\)</span> for which <span class="math inline">\(y_i = 0\)</span> and those for which <span class="math inline">\(y_i = 1\)</span>.</p>
</div>
</section>
<section id="non-overlap-situation" class="slide level2">
<h2>Non-Overlap Situation</h2>
<div class="fragment">
<p>Mathematically, there is non-overlap if there exists <span class="math inline">\(\alpha \in \mathbb{R}^p\)</span> such that</p>
<p><span class="math display">\[\begin{cases}
\text{for all } i \text{ such that } y_i = 0, &amp; \alpha^T x_i \geq 0 \\
\text{for all } i \text{ such that } y_i = 1, &amp; \alpha^T x_i \leq 0
\end{cases}\]</span></p>
</div>
</section>
<section id="illustration-of-non-overlap-situation" class="slide level2">
<h2>Illustration of Non-Overlap Situation</h2>

<img data-src="../images/non_recouvrement.png" class="r-stretch"></section>
<section id="non-overlap-and-existence" class="slide level2">
<h2>Non-Overlap and Existence</h2>
<div class="fragment">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Proposition (admitted)</strong></p>
</div>
<div class="callout-content">
<p>In case of non-overlap, the estimator <span style="background-color: orange;"><span class="math inline">\(\hat{\beta}\)</span> does not exist</span>, in the sense that <span class="math inline">\(L(\beta)\)</span> is maximal when <span class="math inline">\(\|\beta\| \to \infty\)</span> (in one or several directions).</p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>For all <span class="math inline">\(x\)</span>, <span style="background-color: lightblue;"><span class="math inline">\(\hat{p}(x) = \in \{0,1\}\)</span></span>, depending on the position of <span class="math inline">\(x\)</span> relative to the separating hyperplane.</p>
</div>
<div class="fragment">
<p>Nevertheless, there is a “dead zone” in the middle of the <span class="math inline">\(2\)</span> point clouds, because the <span style="background-color: orange;">separating hyperplane is not necessarily unique</span>.</p>
</div>
</section>
<section id="beyond-the-dead-zone" class="slide level2">
<h2>Beyond the Dead Zone</h2>
<div class="fragment">
<p>Beyond this dead zone, classification is very simple (<span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>).</p>
</div>
<div class="fragment">
<p>But no interpretation of the model is possible (the OR are worth <span class="math inline">\(0\)</span> or <span class="math inline">\(+\infty\)</span>).</p>
</div>
</section>
<section id="existence-and-uniqueness-of-mle" class="slide level2">
<h2>Existence and Uniqueness of MLE</h2>
<div class="fragment">
<p>We say <span style="background-color: yellow;">there is overlap</span> when no hyperplane can separate the red points from the blue points.</p>
</div>
<div class="fragment">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Proposition (admitted)</strong></p>
</div>
<div class="callout-content">
<p>If <span class="math inline">\(\text{rank}(X) = p\)</span> and <span style="background-color: yellow;">there is overlap</span>, then the MLE exists and is unique.</p>
</div>
</div>
</div>
<p>Under these conditions, we <span style="background-color: yellow;">can therefore search for the MLE</span> using the Newton-Raphson algorithm.</p>
<ol type="1">
<li class="fragment"><p>the maximum exists,</p></li>
<li class="fragment"><p>the function to optimize is strictly concave and there is therefore no local maximum, only a global maximum.</p></li>
</ol>
</div>
</section>
<section id="fisher-information-recall" class="slide level2">
<h2>Fisher Information (Recall)</h2>
<div class="fragment">
<p>Let <span class="math inline">\(X\)</span> be the design matrix (whose rows are the vectors <span class="math inline">\(x_i\)</span>).</p>
</div>
<div class="fragment">
<p>Let <span class="math inline">\(J_n(\beta)\)</span> be the Fisher information matrix:</p>
<div class="square-def">
<p><span class="math display">\[J_n(\beta) = -E\left[\frac{\partial^2 L}{\partial \beta^2}(\beta) \right]\]</span></p>
</div>
</div>
</section>
<section id="asymptotic-efficiency" class="slide level2">
<h2>Asymptotic Efficiency</h2>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Proposition (admitted)</strong></p>
</div>
<div class="callout-content">
<p>In the logistic regression model, <span style="background-color: yellow;">if</span></p>
<ol type="1">
<li class="fragment">the distribution of the regressors <span class="math inline">\((X_1, \ldots, X_p)\)</span> has compact support,</li>
<li class="fragment"><span class="math inline">\(\text{rank}(X) = p\)</span>,</li>
<li class="fragment">the smallest eigenvalue of <span class="math inline">\(X^T X\)</span> tends to infinity with <span class="math inline">\(n\)</span>,</li>
</ol>
<p><span style="background-color: yellow;">then</span></p>
<ol type="1">
<li class="fragment"><p>the maximum likelihood estimator <span class="math inline">\(\hat{\beta}\)</span> is consistent;</p></li>
<li class="fragment"><p><span class="math inline">\(J_n(\beta)^{1/2}(\hat{\beta} - \beta) \xrightarrow{L} N(0, I_p)\)</span></p></li>
</ol>
<p>where <span class="math inline">\(I_p\)</span> is the identity matrix of size <span class="math inline">\(p\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="comments" class="slide level2">
<h2>Comments</h2>
<div class="fragment">
<p>Under these conditions, the MLE therefore exists for sufficiently large <span class="math inline">\(n\)</span>. In fact, there is necessarily overlap when <span class="math inline">\(n\)</span> is large.</p>
</div>
<div class="fragment">
<p>It is asymptotically efficient (= minimal asymptotic variance)</p>
</div>
<div class="fragment">
<p>The Fisher information matrix <span class="math inline">\(J_n(\beta)\)</span> can be calculated</p>
</div>
<div class="fragment">
<p>We will be able to rely on asymptotic normality to perform tests and construct confidence intervals</p>
</div>
</section>
<section id="comparison-with-linear-regression" class="slide level2">
<h2>Comparison with Linear Regression</h2>
<div class="fragment">
<p>The formula for <span class="math inline">\(\hat{\beta}\)</span> is <span style="background-color: lightgreen;">explicit</span>: <span class="math inline">\(\hat{\beta} = (X^T X)^{-1} X^T Y\)</span>;</p>
</div>
<div class="fragment">
<p>Its expectation and variance are <span style="background-color: lightgreen;">explicit</span>;</p>
</div>
<div class="fragment">
<p>In the Gaussian model (<span class="math inline">\(Y|X\)</span> Gaussian), the distribution of <span class="math inline">\(\hat{\beta}\)</span> is <span style="background-color: lightgreen;">explicit</span>, which allows constructing exact tests (Student, Fisher).</p>
</div>
<div class="fragment">
<p>If the model is not Gaussian, these tests are valid asymptotically.</p>
</div>
</section>
<section id="comparison-with-linear-regression-1" class="slide level2">
<h2>Comparison with Linear Regression</h2>
<div class="fragment">
<p><span style="background-color: orange;">No explicit</span> formula for <span class="math inline">\(\hat{\beta}\)</span>, the solution is obtained numerically;</p>
</div>
<div class="fragment">
<p>We know neither the bias nor the variance of <span class="math inline">\(\hat{\beta}\)</span>;</p>
</div>
<div class="fragment">
<p>The distribution of <span class="math inline">\(Y|X\)</span> is simple (a Bernoulli), but we don’t know the distribution of <span class="math inline">\(\hat{\beta}\)</span>.</p>
</div>
<div class="fragment">
<p>We only know its asymptotic distribution.</p>
</div>
<div class="fragment">
<p>We’ll do <span style="background-color: orange;">asymptotic tests</span>!</p>
</div>
</section></section>
<section>
<section id="tests-and-confidence-intervals" class="title-slide slide level1 center">
<h1>Tests and Confidence Intervals</h1>

</section>
<section id="asymptotic-framework" class="slide level2">
<h2>Asymptotic Framework</h2>
<div class="fragment">
<p>Under “good conditions”,</p>
<div class="square-def">
<p><span class="math display">\[J_n(\beta)^{1/2}(\hat{\beta} - \beta) \xrightarrow{L} N(0, I_p)\]</span></p>
</div>
<p>where <span class="math inline">\(J_n(\beta)\)</span> is the Fisher information matrix.</p>
</div>
<div class="fragment">
<p>To build asymptotic tests, we need to understand <span class="math inline">\(J_n(\beta)\)</span> and be able to estimate it.</p>
</div>
</section>
<section id="computation-of-j_nbeta" class="slide level2">
<h2>Computation of <span class="math inline">\(J_n(\beta)\)</span></h2>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[J_n(\beta) = -E\left[\frac{\partial^2 L}{\partial \beta^2}(\beta) \bigg| X\right]\]</span></p>
</div>
<p>where <span class="math inline">\(L\)</span> is the log-likelihood of the model.</p>
</div>
<div class="fragment">
<p>From the proof of existence of MLE,</p>
<div class="square-def">
<p><span class="math display">\[J_n(\beta) = \sum_{i=1}^n p_\beta(x_i)(1 - p_\beta(x_i)) x_i x_i^T\]</span></p>
</div>
</div>
</section>
<section id="equivalent-form" class="slide level2">
<h2>Equivalent Form</h2>
<div class="fragment">
<p>We can write equivalently</p>
<div class="square-def">
<p><span class="math display">\[J_n(\beta) = X^T W_\beta X\]</span></p>
</div>
<p>where <span class="math inline">\(X\)</span> is the design matrix and <span class="math inline">\(W_\beta\)</span> is the diagonal matrix</p>
</div>
<div class="fragment">
<div style="font-size: 60%;">
<div class="square-def">
<p><span class="math display">\[W_\beta = \begin{pmatrix}
p_\beta(x_1)(1 - p_\beta(x_1)) &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; p_\beta(x_2)(1 - p_\beta(x_2)) &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; p_\beta(x_n)(1 - p_\beta(x_n))
\end{pmatrix}\]</span></p>
</div>
</div>
</div>
</section>
<section id="estimation" class="slide level2">
<h2>Estimation</h2>
<div class="fragment">
<p>To estimate <span class="math inline">\(J_n(\beta)\)</span>, we simply replace <span class="math inline">\(\beta\)</span> by the MLE <span class="math inline">\(\hat{\beta}\)</span></p>
</div>
<div class="fragment">
<p>Under the same regularity assumptions, we can show that</p>
<div class="square-def">
<p><span class="math display">\[J_n(\hat{\beta})^{1/2}(\hat{\beta} - \beta) \xrightarrow{L} N(0, I_p)\]</span></p>
</div>
</div>
</section>
<section id="estimated-variance-of-hat-beta_j" class="slide level2">
<h2>Estimated Variance of <span class="math inline">\(\hat \beta_j\)</span></h2>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[J_n(\hat{\beta})^{1/2}(\hat{\beta} - \beta) \xrightarrow{L} N(0, I_p)\]</span></p>
</div>
</div>
<div class="fragment">
<p>Denoting <span style="background-color: lightblue;"><span class="math inline">\(\hat{\sigma}_j^2\)</span></span> the <span class="math inline">\(j\)</span>-th diagonal element of <span style="background-color: lightblue;"><span class="math inline">\(J_n(\hat{\beta})^{-1}\)</span></span>, we obtain (admitted):</p>
<div class="square-def">
<p><span class="math display">\[\frac{\hat{\beta}_j - \beta_j}{\hat{\sigma}_j} \xrightarrow{L} N(0, 1)\]</span></p>
</div>
</div>
</section>
<section id="confidence-interval" class="slide level2">
<h2>Confidence Interval</h2>
<div class="fragment">
<p>We deduce a confidence interval for <span class="math inline">\(\beta_j\)</span>, at asymptotic confidence level <span class="math inline">\(1 - \alpha\)</span>:</p>
<div class="square-def">
<p><span class="math display">\[\text{CI}_{1-\alpha}(\beta_j) = \left[\hat{\beta}_j - q_{1-\alpha/2}\hat{\sigma}_j \,;\, \hat{\beta}_j + q_{1-\alpha/2}\hat{\sigma}_j\right]\]</span></p>
</div>
<p>where <span class="math inline">\(q(1 - \alpha/2)\)</span> is the quantile of order <span class="math inline">\(1 - \alpha/2\)</span> of the <span class="math inline">\(N(0, 1)\)</span> distribution.</p>
</div>
<div class="fragment">
<p>We verify that we have <span style="background-color: lightblue;"><span class="math inline">\(\P(\beta_j \in \text{CI}_{1-\alpha}(\beta_j)) \to 1 - \alpha\)</span></span>.</p>
</div>
</section>
<section id="significance-test-for-one-coefficient" class="slide level2">
<h2>Significance Test for One Coefficient</h2>
<div class="fragment">
<p>We want to test <span style="background-color: yellow;"><span class="math inline">\(H_0: \beta_j = 0\)</span> against <span class="math inline">\(H_1: \beta_j \neq 0\)</span></span>.</p>
<p>Under <span class="math inline">\(H_0\)</span> we know that <span style="background-color: lightblue;"><span class="math inline">\(\frac{\hat{\beta}_j}{\hat{\sigma}_j} \xrightarrow{L} N(0, 1)\)</span></span></p>
<p>We deduce a critical region at asymptotic level <span class="math inline">\(\alpha\)</span>:</p>
<div class="square-def">
<p><span class="math display">\[\mathcal R_\alpha = \left\{\frac{|\hat{\beta}_j|}{\hat{\sigma}_j} &gt; q_{1-\alpha/2}\right\}\]</span></p>
</div>
</div>
<div class="fragment">
<p>Indeed <span class="math inline">\(P_{H_0}(\mathcal R_\alpha) \to \alpha\)</span>.</p>
<p>This test is called the Wald test. (As any other test that relies on asymptotic normality)</p>
</div>
</section>
<section id="p-value" class="slide level2">
<h2>P-value</h2>
<div class="fragment">
<p>Denoting <span class="math inline">\(\Phi\)</span> the cdf of the <span class="math inline">\(\mathcal N(0, 1)\)</span> distribution, the p-value of the test equals</p>
<div class="square-def">
<p><span class="math display">\[p\text{-value} = 2\left(1 - \Phi\left(\frac{|\hat{\beta}_j|}{\hat{\sigma}_j}\right)\right)\]</span></p>
</div>
</div>
</section>
<section id="example-in-r" class="slide level2">
<h2>Example in R</h2>
<div class="fragment">
<div style="font-size: 50%;">
<table class="caption-top">
<colgroup>
<col style="width: 17%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 17%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Estimate</th>
<th>Std. Error</th>
<th>z value</th>
<th>Pr(&gt;</th>
<th>z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td>-3.9564361</td>
<td>0.3155529</td>
<td>-12.538</td>
<td>&lt; 2e-16</td>
<td>***</td>
</tr>
<tr class="even">
<td>AGE</td>
<td>0.0640837</td>
<td>0.0123960</td>
<td>5.170</td>
<td>2.34e-07</td>
<td>***</td>
</tr>
<tr class="odd">
<td>I(AGE^2)</td>
<td>-0.0006758</td>
<td>0.0001260</td>
<td>-5.364</td>
<td>8.14e-08</td>
<td>***</td>
</tr>
<tr class="even">
<td>DBP</td>
<td>0.0121546</td>
<td>0.0033775</td>
<td>3.599</td>
<td>0.00032</td>
<td>***</td>
</tr>
<tr class="odd">
<td>SEXEFEMME</td>
<td>0.5155651</td>
<td>0.0776229</td>
<td>6.642</td>
<td>3.10e-11</td>
<td>***</td>
</tr>
<tr class="even">
<td>WALK1</td>
<td>-0.4042257</td>
<td>0.0913195</td>
<td>-4.426</td>
<td>9.58e-06</td>
<td>***</td>
</tr>
<tr class="odd">
<td>ACTIV1</td>
<td>-0.6573558</td>
<td>0.1150226</td>
<td>-5.715</td>
<td>1.10e-08</td>
<td>***</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="fragment">
<p>Each columns corresponds resp. to</p>
<ul>
<li><span class="math inline">\(\hat \beta_j\)</span></li>
<li><span class="math inline">\(\hat \sigma_j\)</span></li>
<li><span class="math inline">\(\hat \beta_j/\hat \sigma_j\)</span> (z-score).</li>
</ul>
</div>
</section>
<section id="estimation-of-an-odds-ratio" class="slide level2">
<h2>Estimation of an Odds-Ratio</h2>
<div class="fragment">
<p>We consider two individuals <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> who differ only by their regressor <span class="math inline">\(j\)</span>. Then,</p>
<div class="square-def">
<p><span class="math display">\[OR(x_1^{(j)}, x_2^{(j)}) = e^{\beta_j(x_1^{(j)} - x_2^{(j)})}\]</span></p>
</div>
</div>
<div class="fragment">
<p>Do we have <span class="math inline">\(OR(x_1^{(j)}, x_2^{(j)})\approx 1\)</span>?</p>
</div>
<div class="fragment">
<p>The estimation of <span class="math inline">\(OR(x_1^{(j)}, x_2^{(j)})\)</span> is simply</p>
<div class="square-def">
<p><span class="math display">\[\widehat{OR}(x_1^{(j)}, x_2^{(j)}) = e^{\hat{\beta}_j(x_1^{(j)} - x_2^{(j)})}\]</span></p>
</div>
</div>
</section>
<section id="important-example" class="slide level2">
<h2>Important Example</h2>
<div class="fragment">
<p>If regressor <span class="math inline">\(j\)</span> is binary with <span class="math inline">\(x_1^{(j)} = 1\)</span> and <span class="math inline">\(x_2^{(j)} = 0\)</span>, then</p>
<div class="square-def">
<p><span class="math display">\[\widehat{OR}(x_1^{(j)}, x_2^{(j)}) = e^{\hat{\beta}_j}\]</span></p>
</div>
</div>
</section>
<section id="asymptotic-ci-for-an-odds-ratio" class="slide level2">
<h2>Asymptotic CI for an Odds-Ratio</h2>
<div class="fragment">
<p>We have seen that an asymptotic CI at confidence level <span class="math inline">\(1 - \alpha\)</span> for <span class="math inline">\({\beta}_j\)</span> is</p>
<div class="square-def">
<p><span class="math display">\[\text{CI}_{1-\alpha}(\beta_j) = \left[\hat{\beta}_j - q_{1-\alpha/2}\hat{\sigma}_j \,;\, \hat{\beta}_j + q_{1-\alpha/2}\hat{\sigma}_j\right]= [l,r]\]</span></p>
</div>
</div>
<div class="fragment">
<p>If <span class="math inline">\(x_1^{(j)} &gt; x_2^{(j)}\)</span>, an asymptotic CI for <span class="math inline">\(OR(x_1^{(j)}, x_2^{(j)})= e^{\beta_j(x^{(j)}_1 - x^{(j)}_2)}\)</span> at level <span class="math inline">\(1 - \alpha\)</span> is</p>
<div class="square-def">
<p><span class="math display">\[\text{CI}_{1-\alpha}(OR(x_1^{(j)}, x_2^{(j)})) = \left[e^{l(x_1^{(j)} - x_2^{(j)})}, e^{r(x_1^{(j)} - x_2^{(j)})}\right]\]</span></p>
</div>
</div>
</section>
<section id="significance-test-for-an-odds-ratio" class="slide level2">
<h2>Significance Test for an Odds-Ratio</h2>
<div class="fragment">
<p>We generally want to compare <span class="math inline">\(OR(x_1^{(j)}, x_2^{(j)})\)</span> to <span class="math inline">\(1\)</span>.</p>
<div class="square-def">
<p><span class="math display">\[OR(x_1^{(j)}, x_2^{(j)}) = 1 \Leftrightarrow e^{\beta_j(x_1^{(j)} - x_2^{(j)})} = 1 \Leftrightarrow \beta_j = 0\]</span></p>
</div>
</div>
</section>
<section id="two-sided-test" class="slide level2">
<h2>Two-Sided Test</h2>
<div class="fragment">
<div class="square-def">
<p><span class="math inline">\(H_0: OR(x_1^{(j)}, x_2^{(j)}) = 1\)</span> VS <span class="math inline">\(H_1: OR(x_1^{(j)}, x_2^{(j)}) \neq 1\)</span></p>
</div>
</div>
<div class="fragment">
<p>amounts to testing <span style="background-color: lightblue;"><span class="math inline">\(H_0: \beta_j = 0\)</span> against <span class="math inline">\(H_1: \beta_j \neq 0\)</span></span>. The Rejection region at level <span class="math inline">\(\alpha\)</span> is</p>
</div>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[\mathcal R_\alpha = \left\{\frac{|\hat{\beta}_j|}{\hat{\sigma}_j} &gt; q_{1-\alpha/2}\right\}\]</span></p>
</div>
</div>
</section>
<section id="one-sided-tests" class="slide level2">
<h2>One-Sided Tests</h2>
<div class="fragment">
<p>Nevertheless, for ORs, we <span style="background-color: yellow;">often prefer one-sided tests</span>.</p>
</div>
<div class="fragment">
<div class="square-def">
<p><span class="math inline">\(H_0: OR(x_1^{(j)}, x_2^{(j)}) = 1\)</span> VS <span class="math inline">\(H_1: OR(x_1^{(j)}, x_2^{(j)}) &gt; 1\)</span></p>
</div>
</div>
<div class="fragment">
<p>If <span class="math inline">\(x_1^{(j)} &gt; x_2^{(j)}\)</span>. Since <span style="background-color: lightblue;"><span class="math inline">\(OR(x_1^{(j)}, x_2^{(j)}) \geq 1 \Leftrightarrow \beta_j \geq 0\)</span></span> rejection region at level <span class="math inline">\(\alpha\)</span> is</p>
<div class="square-def">
<p><span class="math display">\[\mathcal R_{\alpha}=\left\{\frac{\hat{\beta}_j}{\hat{\sigma}_j} &gt; q_{1-\alpha}\right\}\]</span></p>
</div>
</div>
</section></section>
<section>
<section id="deviance" class="title-slide slide level1 center">
<h1>Deviance</h1>

</section>
<section id="saturated-model" class="slide level2">
<h2>Saturated Model</h2>
<div class="fragment">
<p>Suppose we have <span class="math inline">\(n\)</span> observations <span class="math inline">\((Y_1, \dots, Y_n)\)</span> and <span class="math inline">\((X_1, \dots, X_n)\)</span> (categorical)</p>
</div>
<div class="fragment">
<p>Here <span class="math inline">\(X_k\)</span> can represent the vector <span class="math inline">\(X_k = (X^{(1)}_k, \dots, X^{(p)}_k)^T\)</span>.</p>
</div>
<div class="fragment">
<p>Assume that indivudal are iid, with <span style="background-color: lightblue;"><span class="math inline">\(\mathbb P(Y=1|X_k=x) = p(x)\)</span></span>.</p>
</div>
<div class="fragment">
<p>How do we estimate <span class="math inline">\(p(x)\)</span>?</p>
</div>
</section>
<section id="saturated-estimator" class="slide level2">
<h2>Saturated Estimator</h2>
<div class="fragment">
<p>Suppose we have <span class="math inline">\(n\)</span> observations <span class="math inline">\((Y_1, \dots, Y_n)\)</span> and <span class="math inline">\((X_1, \dots, X_n)\)</span></p>
</div>
<div class="fragment">
<p><span style="background-color: lightblue;"><span class="math inline">\(n(x) = |\{k:~ X_k = x\}|\)</span></span> (number of indiv. <span class="math inline">\(k\)</span> s.t. <span class="math inline">\(X_k=x\)</span>)</p>
</div>
<div class="fragment">
<p><span style="background-color: lightblue;"><span class="math inline">\(n_1(x) = |\{k:~ X_k = x ~~\text{and}~~Y_k=1\}|\)</span></span></p>
</div>
<div class="fragment">
<p>The saturated model is one that estimates <span class="math inline">\(p(x)\)</span>, for an observed <span class="math inline">\(x\)</span>, by</p>
<div class="square-def">
<p><span class="math display">\[\hat{p}_{\text{sat}}(x) = \frac{n_1(x)}{n(x)}\]</span></p>
</div>
</div>
</section>
<section id="remark" class="slide level2">
<h2>Remark</h2>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[\hat{p}_{\text{sat}}(x) = \frac{n_1(x)}{n(x)}\]</span></p>
</div>
<p><span style="background-color: yellow;">If all observations are distinct</span>, i.e., each observed <span class="math inline">\(x\)</span> is only for a single individual, then for an observed <span class="math inline">\(x\)</span>:</p>
</div>
<div class="fragment">
<p><span class="math inline">\(n(x) = 1\)</span>, <span class="math inline">\(n_1(x) \in \{0,1\}\)</span>, and <span class="math inline">\(\hat{p}_{\text{sat}}(x) = 0\)</span> or <span class="math inline">\(1\)</span>.</p>
</div>
</section>
<section id="remarks-1" class="slide level2">
<h2>Remarks</h2>
<div class="fragment">
<p>The saturated model is the <span style="background-color: yellow;">simplest model</span> to imagine.</p>
</div>
<div class="fragment">
<p>It fits the data perfectly.</p>
</div>
<div class="fragment">
<p>However, it has <span style="background-color: orange;">no explanatory power</span> (effect of regressors on <span class="math inline">\(Y\)</span>?).</p>
</div>
<div class="fragment">
<p>And it says nothing about <span class="math inline">\(p(x)\)</span> if <span class="math inline">\(x\)</span> is not observed.</p>
</div>
<div class="fragment">
<p>It will serves as a <span style="background-color: yellow;">reference</span> for fit</p>
</div>
</section>
<section id="likelihood-of-saturated-estimator" class="slide level2">
<h2>Likelihood of Saturated Estimator</h2>
<div class="fragment">
<p>For the saturated model with probabilities <span class="math inline">\(p(x)\)</span>, the Log-likelihood is:</p>
<div style="font-size: 80%;">
<div class="square-def">
<p><span class="math display">\[L(y_1, \ldots, y_n|x_1, \ldots, x_n) = \sum_{i=1}^n y_i \ln(p(x_i)) + (1 - y_i) \ln(1 - p(x_i))\]</span></p>
</div>
</div>
</div>
<div class="fragment">
<p>The saturated model minimizes this likelihood, and we denote</p>
<div style="font-size: 80%;">
<div class="square-def">
<p><span class="math display">\[L_{\text{sat}} = \sum_{i=1}^n y_i \ln(\hat p_{\text{sat}}(x_i)) + (1 - y_i) \ln(1 - \hat p_{\text{sat}}(x_i))\]</span></p>
</div>
</div>
</div>
</section>
<section id="case-1-distinct-observations" class="slide level2">
<h2>Case 1: Distinct Observations</h2>
<div class="fragment">
<p>If all observations <span class="math inline">\(x_i\)</span> are distinct, we have <span class="math inline">\(\hat{p}_{\text{sat}}(x_i) = y_i\)</span> with <span class="math inline">\(y_i \in \{0, 1\}\)</span>. We thus have</p>
<div class="square-def">
<p><span class="math display">\[L_{\text{sat}} = 0\]</span></p>
</div>
</div>
<div class="fragment">
<p>The saturated estimator has highest possible log-likelihood: it <span style="background-color: orange;">fits the data perfectly</span> (too well).</p>
</div>
</section>
<section id="case-2-non-distinct-observations" class="slide level2">
<h2>Case 2: Non-Distinct Observations</h2>
<div class="fragment">
<p>If the observations <span style="background-color: yellow;"><span class="math inline">\(x_i\)</span> are not distinct</span>, we obtain</p>
<div style="font-size: 80%;">
<div class="square-def">
<p><span class="math display">\[L_{\text{sat}} = \sum_x \left[n_1(x) \ln\left(\frac{n_1(x)}{n(x)}\right) + (n(x) - n_1(x)) \ln\left(1 - \frac{n_1(x)}{n(x)}\right)\right]\]</span></p>
</div>
</div>
<p>where the sum runs over the set of values <span class="math inline">\(x\)</span> taken by the <span class="math inline">\(x_i\)</span>.</p>
</div>
</section>
<section id="deviance-1" class="slide level2">
<h2>Deviance</h2>
<div class="fragment">
<p>The deviance of a model measures how much this model <span style="background-color: yellow;">deviates from the saturated model</span> (the ideal model in terms of likelihood).</p>
</div>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[D = 2(L_{\text{sat}} - L_{\text{mod}})\]</span></p>
</div>
<p>where <span class="math inline">\(L_{\text{mod}}\)</span> denotes the log-likelihood for the model parameters.</p>
</div>
<div class="fragment">
<p>We always have <span style="background-color: lightblue;"><span class="math inline">\(D \geq 0\)</span></span>.</p>
</div>
<div class="fragment">
<p>If all observations are distinct, <span class="math inline">\(L_{\text{sat}} = 0\)</span> therefore <span style="background-color: lightblue;"><span class="math inline">\(D = -2L_{\text{mod}}\)</span></span></p>
</div>
</section>
<section id="role-of-deviance-and-computation-in-r" class="slide level2">
<h2>Role of Deviance and Computation in R</h2>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[D = 2(L_{\text{sat}} - L_{\text{mod}})\]</span></p>
</div>
</div>
<div class="fragment">
<p>Deviance plays the role of the SSR of a linear model: <span style="background-color: yellow;">the higher the deviance, the less well the model is fitted</span> to the data.</p>
</div>
<div class="fragment">
<p><span style="background-color: yellow;">In R</span>, The returned deviance is <span style="background-color: yellow;"><span class="math inline">\(-2L_{\text{mod}}\)</span></span>: the term <span class="math inline">\(L_{\text{sat}}\)</span> is therefore omitted.</p>
</div>
</section></section>
<section>
<section id="testing" class="title-slide slide level1 center">
<h1>Testing</h1>

</section>
<section id="linear-constraint-test" class="slide level2">
<h2>Linear Constraint Test</h2>
<div class="fragment">
<p>As in linear regression, we would like to test <span style="background-color: lightblue;"><span class="math inline">\(H_0: R\beta = 0\)</span> VS <span class="math inline">\(H_1: R\beta \neq 0\)</span></span></p>
<p>where <span class="math inline">\(R\)</span> is a constraint matrix of size <span style="background-color: lightblue;"><span class="math inline">\((q, p)\)</span></span> of full rank.</p>
</div>
<div class="fragment">
<p>For recall, depending on the choice of <span class="math inline">\(R\)</span> this allows:</p>
<ul>
<li class="fragment"><p>testing the minimum: is there at least one relevant regressor?</p></li>
<li class="fragment"><p>comparing nested models</p></li>
<li class="fragment"><p>examining the collective significance of a family of regressors</p></li>
</ul>
</div>
</section>
<section id="available-procedures" class="slide level2">
<h2>Available Procedures</h2>
<div class="fragment">
<p>In GLM, several test procedures address the problem.</p>
<p><strong>The Wald test</strong>, based on the asymptotic normality of <span class="math inline">\(\hat{\beta}\)</span>, which generalizes the one seen for testing <span class="math inline">\(\beta_j = 0\)</span> against <span class="math inline">\(\beta_j \neq 0\)</span>.</p>
</div>
<div class="fragment">
<p><span style="background-color: yellow;"><strong>The likelihood ratio test</strong></span>, called in this context the <span style="background-color: yellow;">deviance test</span>.</p>
</div>
<div class="fragment">
<p><strong>The score test</strong>, based on the behavior of the gradient of the log-likelihood at the critical point.</p>
</div>
<div class="fragment">
<p><strong>The most used</strong> is the <span style="background-color: yellow;">deviance test</span>.</p>
</div>
</section>
<section id="the-deviance-test-or-likelihood-ratio-test" class="slide level2">
<h2>The Deviance Test (or Likelihood Ratio Test)</h2>
<div class="fragment">
<p>To test <span style="background-color: lightblue;"><span class="math inline">\(H_0: R\beta = 0\)</span> against <span class="math inline">\(H_1: R\beta \neq 0\)</span></span>, the principle of the test is as follows:</p>
</div>
<div class="fragment">
<p>We calculate the MLE in each model to obtain <span class="math inline">\(\hat{\beta}\)</span> in the complete model and <span style="background-color: yellow;"><span class="math inline">\(\hat{\beta}_{H_0}\)</span> in the constrained model</span>.</p>
</div>
<div class="fragment">
<p><strong>Logic</strong>: If <span class="math inline">\(H_0\)</span> is true, the constrained model should be as “likely” as the complete model, so <span style="background-color: yellow;"><span class="math inline">\(L(\hat{\beta})\)</span> and <span class="math inline">\(L(\hat{\beta}_{H_0})\)</span> should be similar</span>.</p>
</div>
</section>
<section id="deviance-test-statistic" class="slide level2">
<h2>Deviance Test Statistic</h2>
<div class="fragment">
<p>The test statistic is the <span style="background-color: yellow;">difference of deviances</span>:</p>
<div class="square-def">
<p><span class="math display">\[D_{H_0} - D_{H_1} = 2\left(L(\hat{\beta}) - L(\hat{\beta}_{H_0})\right)\]</span></p>
</div>
</div>
<div class="fragment">
<p>Under <span class="math inline">\(H_0\)</span>, denoting <span class="math inline">\(q\)</span> the number of constraints, we have the convergence (admitted):</p>
<div class="square-def">
<p><span class="math display">\[D_{H_0} - D_{H_1} = 2\left(L(\hat{\beta}) - L(\hat{\beta}_{H_0})\right) \xrightarrow{L} \chi^2_q\]</span></p>
</div>
</div>
</section>
<section id="rejection-region-and-p-value" class="slide level2">
<h2>Rejection Region and P-value</h2>
<div class="fragment">
<p>The asymp. rejection region at asymptotic level <span class="math inline">\(\alpha\)</span> is therefore</p>
<div class="square-def">
<p><span class="math display">\[\mathcal R_\alpha = \{D_{H_0} - D_{H_1} &gt; \chi^2_{q,1-\alpha}\}\]</span></p>
</div>
<p>where <span class="math inline">\(\chi^2_{q,1-\alpha}\)</span>: quantile <span class="math inline">\(1 - \alpha\)</span> of a <span class="math inline">\(\chi^2_q\)</span> distribution.</p>
</div>
<div class="fragment">
<p>The p-value equals</p>
<div class="square-def">
<p><span class="math display">\[p\text{-value} = 1 - F(D_{H_0} - D_{H_1})\]</span></p>
</div>
<p>where <span class="math inline">\(F\)</span> is the cdf of a <span class="math inline">\(\chi^2_q\)</span> distribution.</p>
</div>
</section>
<section id="special-case-1-significance-test" class="slide level2">
<h2>Special Case 1: Significance Test</h2>
<div class="fragment">
<p>We want to test if a model (having a constant) is significant</p>
</div>
<div class="fragment">
<p>We therefore test <span class="math inline">\(H_0\)</span>: all its <span style="background-color: yellow;">coefficients are zero except the constant</span>. This corresponds to the special case</p>
<div class="square-def">
<p><span class="math inline">\(R = [0 | I_{p-1}]\)</span>.</p>
</div>
</div>
<div class="fragment">
<p>We <span style="background-color: yellow;">compare the deviance of the model to the null deviance <span class="math inline">\(D_0\)</span></span>, corresponding to a model that contains only the constant.</p>
</div>
</section>
<section id="test-statistic" class="slide level2">
<h2>Test Statistic</h2>
<div class="fragment">
<p>The test statistic is <span class="math inline">\(D_0 - D\)</span>. Under <span class="math inline">\(H_0\)</span>, when <span class="math inline">\(n \to \infty\)</span>:</p>
<div class="square-def">
<p><span class="math display">\[D_0 - D \sim \chi^2_{p-1}\]</span></p>
</div>
</div>
<div class="fragment">
<p>The model is therefore significant (relative to the null model) if the sample is in the critical region of asymptotic level <span class="math inline">\(\alpha\)</span>:</p>
<div class="square-def">
<p><span class="math display">\[\mathcal R_\alpha = \{D_0 - D &gt; \chi^2_{p-1,1-\alpha/2}\}\]</span></p>
</div>
</div>
</section>
<section id="special-case-2-nested-models" class="slide level2">
<h2>Special Case 2: Nested Models</h2>
<div class="fragment">
<p>Suppose that model <span style="background-color: yellow;"><span class="math inline">\(1\)</span> (with deviance <span class="math inline">\(D_1\)</span>) is a sub-model of model <span class="math inline">\(2\)</span></span> (with deviance <span class="math inline">\(D_2\)</span>)</p>
</div>
<div class="fragment">
<p>Model <span class="math inline">\(1\)</span> is therefore obtained from model <span class="math inline">\(2\)</span>, with parameter <span class="math inline">\(\beta\)</span>, via a constraint of the type <span class="math inline">\(R\beta = 0\)</span> where <span style="background-color: lightblue;"><span class="math inline">\(R\)</span> is a <span class="math inline">\((q, p)\)</span> matrix</span>.</p>
</div>
<div class="fragment">
<p>Under <span class="math inline">\(H_0: R\beta = 0\)</span>, we have asymptotically <span style="background-color: lightblue;"><span class="math inline">\(D_1 - D_2 \sim \chi^2_q\)</span></span></p>
</div>
<div class="fragment">
<p>Hence the asymptotic test: <span style="background-color: lightblue;"></span>.</p>
<div class="square-def">
<p><span class="math inline">\(\mathcal R_\alpha = \{D_1 - D_2 &gt; \chi^2_{q,1 - \alpha}\}\)</span></p>
</div>
</div>
</section>
<section id="aic-and-bic-criteria" class="slide level2">
<h2>AIC and BIC Criteria</h2>
<div class="fragment">
<p>The AIC and BIC criteria are defined similarly to linear regression, i.e.</p>
<div class="square-def">
<p><span class="math inline">\(\text{AIC} = -2L_{\text{mod}} + 2p\)</span></p>
</div>
<div class="square-def">
<p><span class="math inline">\(\text{BIC} = -2L_{\text{mod}} + \ln(n)p\)</span></p>
</div>
<p>where <span class="math inline">\(L_{\text{mod}}\)</span> is the log-likelihood of the estimated model.</p>
</div>
</section>
<section id="aic-and-bic-criteria-1" class="slide level2">
<h2>AIC and BIC Criteria</h2>
<div class="fragment">
<p>If we ignore saturated likelihood and set <span class="math inline">\(L_{\text{sat}}=0\)</span>,</p>
<div class="square-def">
<p><span class="math inline">\(\text{AIC} = D + 2p\)</span></p>
</div>
<div class="square-def">
<p><span class="math inline">\(\text{BIC} = D + \ln(n)p\)</span></p>
</div>
<p><strong>In practice</strong>, we choose the model having the minimal AIC or BIC</p>
</div>
<div class="fragment">
<p>As in linear regression, we can use automatic selection procedures (backward, forward, etc).</p>
</div>
</section>
<section id="example-obesity-study" class="slide level2">
<h2>Example: Obesity Study</h2>
<div class="fragment">
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a></a>model<span class="ot">=</span><span class="fu">glm</span>(Y<span class="sc">~</span>AGE<span class="sc">+</span>DBP<span class="sc">+</span>SEXE<span class="sc">+</span>ACTIV<span class="sc">+</span>WALK<span class="sc">+</span>MARITAL, <span class="at">family=</span>binomial)</span>
<span id="cb3-2"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment">
<div style="font-size: 60%;">
<table class="caption-top">
<thead>
<tr class="header">
<th>Statistic</th>
<th>Value</th>
<th>Degrees of Freedom</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Null deviance</td>
<td><span class="math inline">\(4610.8\)</span></td>
<td>on <span class="math inline">\(5300\)</span></td>
</tr>
<tr class="even">
<td>Residual deviance</td>
<td><span class="math inline">\(4459.5\)</span></td>
<td>on <span class="math inline">\(5290\)</span></td>
</tr>
<tr class="odd">
<td>AIC</td>
<td><span class="math inline">\(4481.5\)</span></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="fragment">
<p>The model deviance is therefore <span class="math inline">\(D = 4459.5\)</span>.</p>
<p><strong>Significance Test</strong>: We compare <span class="math inline">\(D\)</span> to the null deviance <span class="math inline">\(D_0 = 4610.8\)</span>: <span style="background-color: lightblue;"><span class="math inline">\(D_0 - D = 151.3\)</span></span>. The p-value of the test equals <span style="background-color: lightblue;"><span class="math inline">\(1 - \chi^2_{10}(151.3) \approx 0\)</span></span> where <span class="math inline">\(\chi^2_{10}\)</span> is the cdf of a <span class="math inline">\(\chi^2_{10}\)</span>.</p>
</div>
<div class="fragment">
<p>The model is significant.</p>
</div>
</section>
<section id="example-significance-test-of-marital" class="slide level2">
<h2>Example: Significance Test of MARITAL</h2>
<div class="fragment">
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a></a>model<span class="ot">=</span><span class="fu">glm</span>(Y<span class="sc">~</span>AGE<span class="sc">+</span>DBP<span class="sc">+</span>SEXE<span class="sc">+</span>ACTIV<span class="sc">+</span>WALK, <span class="at">family=</span>binomial) <span class="co"># We want to test if `MARITAL` is significant</span></span>
<span id="cb4-2"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment">
<div style="font-size: 60%;">
<table class="caption-top">
<thead>
<tr class="header">
<th>Statistic</th>
<th>Value</th>
<th>Degrees of Freedom</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Null deviance</td>
<td><span class="math inline">\(4610.8\)</span></td>
<td>on <span class="math inline">\(5300\)</span></td>
</tr>
<tr class="even">
<td>Residual deviance</td>
<td><span class="math inline">\(4462.7\)</span></td>
<td>on <span class="math inline">\(5295\)</span></td>
</tr>
<tr class="odd">
<td>AIC</td>
<td><span class="math inline">\(4474.7\)</span></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="fragment">
<p>The deviance is now <span class="math inline">\(D_2 = 4462.7\)</span>. To compare with the previous model, we calculate: <span style="background-color: lightblue;"><span class="math inline">\(D_2 - D = 3.2\)</span></span>.</p>
</div>
<div class="fragment">
<p>The p-value of the test equals <span style="background-color: lightblue;"><span class="math inline">\(1 - F_5(3.2) \approx 0.67\)</span></span>, where <span class="math inline">\(F_5\)</span>: cdf of a <span class="math inline">\(\chi^2_5\)</span>.</p>
<p>We therefore <span style="background-color: yellow;">accept <span class="math inline">\(H_0\)</span></span>: the coefficients related to <span style="background-color: yellow;">MARITAL are zero</span>. (Also confirmed with AIC)</p>
</div>
</section>
<section id="example-significance-test-of-age2" class="slide level2">
<h2>Example: Significance Test of AGE<span class="math inline">\(~^2\)</span></h2>
<div class="fragment">
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a></a>model<span class="ot">=</span><span class="fu">glm</span>(Y∼AGE<span class="sc">+</span><span class="fu">I</span>(AGE2 )<span class="sc">+</span>DBP<span class="sc">+</span>SEXE<span class="sc">+</span>WALK<span class="sc">+</span>ACTIV, <span class="at">family=</span>binomial) <span class="co"># We add AGE^2</span></span>
<span id="cb5-2"><a></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div style="font-size: 60%;">
<table class="caption-top">
<thead>
<tr class="header">
<th>Statistic</th>
<th>Value</th>
<th>Degrees of Freedom</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Null deviance</td>
<td><span class="math inline">\(4610.8\)</span></td>
<td>on <span class="math inline">\(5300\)</span></td>
</tr>
<tr class="even">
<td>Residual deviance</td>
<td><span class="math inline">\(4439.5\)</span></td>
<td>on <span class="math inline">\(5294\)</span></td>
</tr>
<tr class="odd">
<td>AIC</td>
<td><span class="math inline">\(4453.5\)</span></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="fragment">
<p>The deviance test with the previous model has p-value <span style="background-color: lightblue;"><span class="math inline">\(1 - F_1(4462.7 - 4439.5) = 1 - F_1(23.2) \approx 10^{-6}\)</span></span></p>
</div>
<div class="fragment">
<p>This model is <span style="background-color: yellow;">therefore preferable</span>, (confirmed with AIC).</p>
</div>
<div class="fragment">
<p>However, we <span style="background-color: orange;">cannot compare this model with the first</span> one by deviance test because they are <span style="background-color: orange;">not nested</span>.</p>
</div>
<div class="fragment">
<p>We <span style="background-color: lightgreen;">can however compare their AIC</span>: this model is preferable.</p>
</div>
</section></section>
<section>
<section id="prediction" class="title-slide slide level1 center">
<h1>Prediction</h1>

</section>
<section id="setting-and-objective" class="slide level2">
<h2>Setting and Objective</h2>
<div class="fragment">
<p>Suppose we are interested in a <span style="background-color: yellow;">new individual</span> for whom</p>
<ul>
<li class="fragment">we know their characteristics <span class="math inline">\(x \in \mathbb{R}^p\)</span>,</li>
<li class="fragment">we do not know their <span class="math inline">\(Y\)</span>.</li>
</ul>
</div>
<div class="fragment">
<p>We want to <span style="background-color: yellow;">predict <span class="math inline">\(Y\)</span></span> for this <span style="background-color: yellow;">new individual</span>.</p>
</div>
</section>
<section id="recall-in-the-logit-model" class="slide level2">
<h2>Recall in the Logit Model</h2>
<div class="fragment">
<p>If we have <span style="background-color: yellow;">fitted a logistic regression</span> model, we can estimate</p>
<div class="square-def">
<p><span class="math display">\[p_\beta(x) = P(Y = 1|X = x)\]</span></p>
</div>
<p>by</p>
</div>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[p_{\hat{\beta}}(x) = \text{logit}^{-1}(x^T \hat{\beta}) = \frac{e^{x^T \hat{\beta}}}{1 + e^{x^T \hat{\beta}}}\]</span></p>
</div>
</div>
</section>
<section id="outline-for-prediction" class="slide level2">
<h2>Outline for Prediction</h2>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[p_\beta(x) = P(Y = 1|X = x)\]</span></p>
</div>
<p>We will see:</p>
<ol type="1">
<li class="fragment"><p>how to construct a <span style="background-color: yellow;">confidence interval around the estimation <span class="math inline">\(p_{\hat{\beta}}(x)\)</span></span>;</p></li>
<li class="fragment"><p>how to exploit this estimation to <span style="background-color: yellow;">classify the new individual</span> in category <span class="math inline">\(Y = 0\)</span> or <span class="math inline">\(Y = 1\)</span>.</p></li>
</ol>
</div>
</section>
<section id="ci-asymptotic-distribution-of-p_betax" class="slide level2">
<h2>CI: Asymptotic Distribution of <span class="math inline">\(p_\beta(x)\)</span></h2>
<div class="fragment">
<p>We know that when <span class="math inline">\(n \to \infty\)</span>:</p>
<div class="square-def">
<p><span class="math display">\[\hat{\beta} \sim N(\beta, (X^T W_{\hat{\beta}} X)^{-1})\]</span></p>
</div>
<ul>
<li class="fragment"><span class="math inline">\(X=(X^{(1)}, \dots, X^{(p)})\)</span> is the <span class="math inline">\(n \times p\)</span> <span style="background-color: yellow;">design matrix</span></li>
<li class="fragment"><span class="math inline">\(W_{\hat{\beta}}\)</span> is the <span class="math inline">\(n \times n\)</span> <span style="background-color: yellow;">diagonal matrix</span> with coefs <span style="background-color: lightblue;"><span class="math inline">\(p_{\hat \beta}(x_i)(1-p_{\hat \beta}(x_i))\)</span></span></li>
</ul>
</div>
</section>
<section id="ci-for-linear-predictor" class="slide level2">
<h2>CI for Linear Predictor</h2>
<div class="fragment">
<p>We deduce that when <span class="math inline">\(n \to +\infty\)</span>, <span style="background-color: lightblue;"><span class="math inline">\(x^T \hat{\beta} \sim N(x^T \beta, x^T (X^T W_{\hat{\beta}} X)^{-1} x)\)</span></span>, and the asymptotic CI of <span class="math inline">\(x^T\beta\)</span>:</p>
</div>
<div class="fragment">
<div class="square-def">
<p><span class="math display">\[\text{CI}_{1-\alpha}(x^T \beta) = \left[x^T \hat{\beta} \pm q_{1-\alpha/2} \sqrt{x^T (X^T W_{\hat{\beta}} X)^{-1} x}\right]\]</span></p>
</div>
</div>
</section>
<section id="ci-for-probability-p_betax" class="slide level2">
<h2>CI for Probability <span class="math inline">\(p_{\beta}(x)\)</span></h2>
<div class="fragment">
<p>Since <span style="background-color: lightblue;"><span class="math inline">\(p_{\hat{\beta}}(x) = \text{logit}^{-1}(x^T \hat{\beta})\)</span></span>, we have therefore by application of the increasing function <span class="math inline">\(\text{logit}^{-1}\)</span>, the CI at asymptotic level <span class="math inline">\(1 - \alpha\)</span>:</p>
</div>
<div class="fragment">
<div style="font-size: 80%;">
<div class="square-def">
<p><span class="math display">\[\text{CI}_{1-\alpha}(p_\beta(x)) = \left[\text{logit}^{-1}\left(x^T \hat{\beta} \pm q_{1-\alpha/2} \sqrt{x^T (X^T W_{\hat{\beta}} X)^{-1} x}\right)\right]\]</span></p>
</div>
</div>
</div>
</section>
<section id="classification" class="slide level2">
<h2>Classification</h2>
<div class="fragment">
<p>We have estimated <span class="math inline">\(p_\beta(x) = P(Y = 1|X = x)\)</span> by <span class="math inline">\(p_{\hat{\beta}}(x)\)</span>.</p>
</div>
<div class="fragment">
<p>For a <span style="background-color: yellow;">threshold to choose <span class="math inline">\(s \in [0, 1]\)</span></span>, we use the rule:</p>
<div class="square-def">
<p><span class="math display">\[\begin{cases}
\text{if } p_{\hat{\beta}}(x) &gt; s, &amp; \hat{Y} = 1 \\
\text{if } p_{\hat{\beta}}(x) &lt; s, &amp; \hat{Y} = 0
\end{cases}\]</span></p>
</div>
</div>
<div class="fragment">
<p>The “natural” choice of threshold is <span class="math inline">\(s = 0.5\)</span> but <span style="background-color: yellow;">this choice can be optimized</span>.</p>
</div>
</section>
<section id="evaluation-of-classification-quality" class="slide level2">
<h2>Evaluation of Classification Quality</h2>
<div class="fragment">
<p>We proceed by <span style="background-color: yellow;">cross-validation</span>:</p>
</div>
<div class="fragment">
<p>Using a <span style="background-color: yellow;">train sample</span>, predict <span class="math inline">\(Y\)</span> on a <span style="background-color: yellow;">test sample</span> and form the <span style="background-color: yellow;">confusion matrix</span>.</p>
</div>
<div class="fragment">
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(Y = 0\)</span></th>
<th><span class="math inline">\(Y = 1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{Y} = 0\)</span></td>
<td>TN</td>
<td>FN</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\hat{Y} = 1\)</span></td>
<td>FP</td>
<td>TP</td>
</tr>
</tbody>
</table>
<p><strong>Reading</strong>: T: true, F:False, N: Negative, P: Positive.</p>
</div>
<div class="fragment">
<p><strong>FP</strong>: false positives: number of individuals who were classified <span style="background-color: yellow;">positive</span> who were actually <span style="background-color: orange;">negative</span></p>
</div>
</section>
<section id="evaluation-of-classification-quality-1" class="slide level2">
<h2>Evaluation of Classification Quality</h2>
<div class="fragment">
<p>The ideal is to have a confusion matrix that is <span style="background-color: yellow;">as diagonal as possible</span>.</p>
</div>
<div class="fragment">
<p>We generally seek to maximize the <span style="background-color: yellow;">following indicators</span>:</p>
</div>
<div class="fragment">
<div class="columns">
<div class="column">
<p>The <strong>sensitivity</strong> (or recall, or true positive rate) estimates <span style="background-color: lightblue;"><span class="math inline">\(\P(\hat{Y} = 1|Y = 1)\)</span></span> by</p>
<div class="square-def">
<p><span class="math display">\[\frac{\text{TP}}{\text{TP} + \text{FN}}\]</span></p>
</div>
</div><div class="column">
<p>The <strong>specificity</strong> (or selectivity, or true negative rate) estimates <span style="background-color: lightblue;"><span class="math inline">\(\P(\hat{Y} = 0|Y = 0)\)</span></span></p>
<div class="square-def">
<p><span class="math display">\[\frac{\text{TN}}{\text{TN} + \text{FP}}\]</span></p>
</div>
</div></div>
</div>
</section>
<section id="other-indicators" class="slide level2">
<h2>Other Indicators</h2>
<div class="fragment">
<p>The <strong>precision</strong> (or positive predictive value) estimates <span class="math inline">\(\P(Y = 1|\hat{Y} = 1)\)</span> by</p>
<div class="square-def">
<p><span class="math inline">\(\frac{\text{TP}}{\text{TP} + \text{FP}}\)</span></p>
</div>
</div>
<div class="fragment">
<p>The <strong><span class="math inline">\(F\)</span>-score</strong> is the harmonic mean between sensitivity and precision:</p>
<div class="square-def">
<p><span class="math display">\[F_1 = 2 \frac{\text{precision} \times \text{sensitivity}}{\text{precision} + \text{sensitivity}}\]</span></p>
</div>
</div>
</section>
<section id="choice-of-threshold-s" class="slide level2">
<h2>Choice of Threshold <span class="math inline">\(s\)</span></h2>
<div class="fragment">
<p>For each threshold <span class="math inline">\(s\)</span>, from a test sample:</p>
<ul>
<li class="fragment">we can form the confusion matrix</li>
<li class="fragment">calculate scores (sensitivity, <span class="math inline">\(F\)</span>-score, etc.)</li>
</ul>
</div>
<div class="fragment">
<p>We finally choose the <span style="background-color: yellow;">optimal threshold <span class="math inline">\(s\)</span></span>, according to the <span style="background-color: yellow;">chosen score</span>.</p>
</div>
</section>
<section id="choosing-the-score" class="slide level2">
<h2>Choosing the score</h2>
<ul>
<li class="fragment">It depends on the context of the study</li>
<li class="fragment">It can be much more serious to wrongly predict <span class="math inline">\(\hat{Y} = 0\)</span> than <span class="math inline">\(\hat{Y} = 1\)</span></li>
</ul>
<div class="fragment">
<p><span class="math inline">\(\hat Y=1\)</span> (treatment) while the patient is <span style="background-color: yellow;">not ill</span> (<span class="math inline">\(Y = 0\)</span>)</p>
</div>
<div class="fragment">
<p><span class="math inline">\(\hat Y=0\)</span> (no treatment) while the patient <span style="background-color: yellow;">has a serious illness</span> (<span class="math inline">\(Y=1\)</span>)</p>
</div>
</section>
<section id="roc-curve" class="slide level2">
<h2>ROC Curve</h2>
<div class="fragment">
<p>We can also plot the ROC curve (TP rate as a function of FP rate for <span class="math inline">\(s \in [0, 1]\)</span>):</p>
<div style="font-size: 80%;">
<div class="square-def">
<p><span class="math inline">\(ROC:~~\mathrm{sensitiv.} = \frac{TP}{TP+FN} = F\left(\frac{FP}{FP+TN}\right) = F(1-\mathrm{specific.})\)</span></p>
</div>
</div>
</div>
<div class="fragment">
<p>The <span style="background-color: yellow;">AUC (area under the curve)</span> is a quality indicator of the model (<span class="math inline">\(0 \leq \text{AUC} \leq 1\)</span>).</p>
</div>
<div class="fragment">
<p>Or equivalently, the <span style="background-color: yellow;">Gini index: <span class="math inline">\(2 \times \text{AUC} - 1\)</span></span>.</p>
</div>
<div class="fragment">
<p><strong>Use</strong>: compare <span class="math inline">\(2\)</span> models by <span style="background-color: yellow;">plotting the 2 ROC curves</span>.</p>
</div>
</section>
<section id="roc-curve-illustration" class="slide level2">
<h2>ROC Curve Illustration</h2>
<div class="fragment">
<div style="text-align: center;">
<p><img data-src="../images/roc.png"></p>
</div>


</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>